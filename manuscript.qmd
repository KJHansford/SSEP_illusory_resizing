---
title: "Illusory Finger Stretching and Somatosensory Responses"
author: ""
bibliography: references-rr.bib
#csl: elife.csl
output:
  bookdown::pdf_document2:
    fig_caption: yes
    toc: no
    keep_tex: true
execute: 
  echo: false
  include: false
  output: false
format: 
  pdf:
    fig-pos: "H"
---

```{r setup, include=FALSE}

processdata <- 0
# the processdata flag has two levels:
# 0 - just produce the manuscript and all analyses and figures from processed EEG data
# 1 - do all analyses from scratch using the raw EEG data


# install R packages
packagelist <- c('tidyverse','ggpubr','ez','ggplot2','jpeg','grid','plotrix','lavaan', 'cowplot', 'ggpubr','rstatix','reticulate','moments','tiff','rmarkdown','tinytex','osfr','FSA','compute.es')  
missingpackages <- packagelist[!packagelist %in% installed.packages()[,1]]
if (length(missingpackages)>0){install.packages(missingpackages)}
toinstall <- packagelist[which(!packagelist %in% (.packages()))]
invisible(lapply(toinstall,library,character.only=TRUE))

# if (!is_tinytex()){install_tinytex()}

# create python environment and install packages
  if (processdata==1){
  install_miniconda()
  use_miniconda('r-reticulate')
  # install_python(version="3.10")
  py_install(c('mne', 'numpy', 'scikit-learn', 'matplotlib', 'pandas', 'openpyxl'))
  }

# check for local files and directories and create/download if missing
if (!dir.exists('local')){dir.create('local')}

figdir <- 'Figures/'
if (!dir.exists(figdir)){dir.create(figdir)}

if (processdata==1){
  if (!dir.exists('local/EEG Data')){dir.create('local/EEG Data')}
}

if (processdata==1){
    for (subj in 1:48){
    if (!dir.exists(paste0('local/EEG Data/P',subj))){dir.create(paste0('local/EEG Data/P',subj))}
  }
  osfproject <- osf_retrieve_node("xc8jq")
  osffiles <- osf_ls_files(osfproject,n_max=100)
  for (subj in 1:48){
    if (!file.exists(paste0('local/EEG Data/P',subj,'/P',subj,'_block1_EEG.fdt'))){
    fid <- which(osffiles$name==paste0('P',subj,'_block1_EEG.fdt'))
    osf_download(osffiles[fid,], path=paste0('local/EEG Data/P',subj),progress=TRUE)
    }
    if (!file.exists(paste0('local/EEG Data/P',subj,'/P',subj,'_block1_EEG.set'))){
    fid <- which(osffiles$name==paste0('P',subj,'_block1_EEG.set'))
    osf_download(osffiles[fid,], path=paste0('local/EEG Data/P',subj),progress=TRUE)
}}}


if (!file.exists('local/subjective data.csv')){
  osfproject <- osf_retrieve_node("edqf5")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='subjective data.csv')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/handedness.csv')){
  osfproject <- osf_retrieve_node("edqf5")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='handedness.csv')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/demographics.csv')){
  osfproject <- osf_retrieve_node("edqf5")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='demographics.csv')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/Allfspec.npy')){
  osfproject <- osf_retrieve_node("h3fbq")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='Allfspec.npy')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/amplitudes1.npy')){
  osfproject <- osf_retrieve_node("h3fbq")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='amplitudes1.npy')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/amplitudes2.npy')){
  osfproject <- osf_retrieve_node("h3fbq")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='amplitudes2.npy')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('local/channames.npy')){
  osfproject <- osf_retrieve_node("h3fbq")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='channames.npy')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}


if (!file.exists('references-rr.bib')){
  osfproject <- osf_retrieve_node("wfu7j")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='references-rr.bib')
  osf_download(osffiles[fid,], progress=TRUE)
}

if (!file.exists('local/montage.csv')){
  osfproject <- osf_retrieve_node("wfu7j")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='montage.csv')
  osf_download(osffiles[fid,], path='local/',progress=TRUE)
}

if (!file.exists('Figures/Augmented Reality System.png')){
  osfproject <- osf_retrieve_node("wfu7j")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='Augmented Reality System.png')
  osf_download(osffiles[fid,], path='Figures/',progress=TRUE)
}

if (!file.exists('Figures/Conditions.png')){
  osfproject <- osf_retrieve_node("wfu7j")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='Conditions.png')
  osf_download(osffiles[fid,], path='Figures/',progress=TRUE)
}

if (!file.exists('Figures/Pilot Data.png')){
  osfproject <- osf_retrieve_node("wfu7j")
  osffiles <- osf_ls_files(osfproject)
  fid <- which(osffiles$name=='Pilot Data.png')
  osf_download(osffiles[fid,], path='Figures/',progress=TRUE)
}

```

```{python SEremoval, include=FALSE}

# code to import raw EEG data and process
if r.processdata==1:

  import os
  # os.system('python3 -m pip install mne numpy scikit-learn matplotlib pandas openpyxl')
  import mne
  import math
  import numpy as np
  import pandas as pd
  import matplotlib.pyplot as plt

  #Suppress console output from MNE (as this gives a lot of output)
  mne.set_log_level('ERROR')

  ## Directories ##

  #Sets base data directory
  datadir = "local/EEG data/"
  outDir = "local/"

  ## Begin ##

  #make zeros arrays for ses to be placed in 
  allses = np.zeros([48,96,62])

  #Set up a dictionary to record participants with erronious numbers of trials. 
  errorDict = {}
  participantList = []

  print('Reading subject...')

  #47 = 46Ps because python
  for subjectno in range(1,49):
    
    #load in subject data  
    subject = (f'P{subjectno}')
    print(f'P{subjectno}', end = ' ')
    participantList.append(f'P{subjectno}')
    
    #Read in data    
    raw_fname = os.path.join(datadir, subject, f'P{subjectno}_block1_EEG.set')
    raw = mne.io.read_raw_eeglab(raw_fname,preload=True)
    
    #load in EEG montage
    ANT_montage = mne.channels.make_standard_montage("standard_1020")
    raw.drop_channels(["HEOG", "VEOG", "M1", "M2"])
    raw.set_montage(ANT_montage)
    
    #Apply 50Hz notch filter
    #filtered = raw.filter(0.2,40)
    filtered = raw.copy().notch_filter(freqs=50)
    
    #extract triggers
    events, event_id = mne.events_from_annotations(filtered)
    
    #Get electrode list
    ch_names = raw.ch_names
    
    #set condition triggers
    legaltriggers = [10,20,30,40]
    
    #make variable for exracted values
    extracted_values = []
    
    #use condition triggers as event triggers
    for trigger in legaltriggers:
        trigger_str = str(trigger)
        if trigger_str in event_id:
            extracted_values.append(event_id[trigger_str])
    
    #define event labels for each condition based on extracted values
    event_dict = {
            "NI": extracted_values[0],
            "NIT": extracted_values[1],
            "MS": extracted_values[2],
            "UV": extracted_values[3]
    }
    
    #Set rejection criteria
    reject_criteria = None   #dict(eeg=200e-6)
    
    #epoch data
    allepochs = mne.Epochs(filtered, events, event_id=event_dict, tmin=0.4,
                           tmax=2.4, baseline=(0.4,2.4), reject=reject_criteria, 
                           preload=True)

    #Check if data is the correct length, if not correct, ignore and add to 
    #error dictionary, if correct, proceed. 
    if len(allepochs) != 96:
        errorDict[f'P{subjectno}'] = len(allepochs)
    else:    
        #get trial data from epochs
        trials = allepochs.get_data()*1000000
        allses[subjectno-1,0:96,0:62] = np.std(trials,axis=2)/np.sqrt(2001)
      
  print('')
  print('The following participants have incorrect trial numbers:')
  for participant, trials in errorDict.items():
    print(f'{participant} : {trials:03} trials')

  #get mean ses from allses
  meanses = np.mean(allses,axis=1)

  #if a value is 0 make it nan
  meanses[meanses==0] = np.nan

  #concatenate the means ses into a vector
  sesvect = np.concatenate(meanses)
  #remove nan values
  sesvect = sesvect[~np.isnan(sesvect)]
  #sort in ascending order
  sesvect.sort()
  #create threshold of top 5% of values
  thd = sesvect[round(len(sesvect)*0.95)]
  #see threshold value
  thd

  #Create a dataframe from meanses 
  meansesDf = pd.DataFrame(meanses)
  meansesDf.insert(0, 'Participant', participantList)

  #Creates a dictionary where key = electrode number, value = electrode name
  electrodeDict = {}
  for num, electrode in enumerate(ch_names):
    electrodeDict[num] = electrode

  #Sets up a participant dictionary and loops over participants
  pDict = {}
  for participant in range(len(meanses)):
    
    #Sets up an electrode list and loops over electrodes
    eList = []  
    for electrode in range(len(ch_names)):
  
        #If means exceed threshhold or are nan, add electrode number to the
        #list. 
        if meanses[participant, electrode] > thd:      
            eList.append(electrode)
        elif math.isnan(meanses[participant, electrode]):
            eList.append(electrode)
    
    #Add over threshhold list to dictionary under participant key
    pDict[f'P{participant+1}'] = eList

  #Convert dictionary to a dataframe and replace all values according to key into
  #values established in the electrodeDict dictionary. 
  electrodeDf = pd.DataFrame.from_dict(pDict, orient='index')
  electrodeDf = electrodeDf.replace(electrodeDict)
  electrodeDf.insert(0, 'Participant', participantList)

  #Save output to spreadsheet
  with pd.ExcelWriter(os.path.join(outDir, 'Electrodes.xlsx')) as writer:
                    meansesDf.to_excel(writer, sheet_name = 'Mean SES', 
                                       index = False)
                    electrodeDf.to_excel(writer, sheet_name = 'Over Thresh', 
                                         index = False)
  electrodeDf.to_csv(os.path.join(outDir, 'Electrodes.csv'), index = False)
  meansesDf.to_csv(os.path.join(outDir, 'Meanses.csv'), index = False)
    

```

```{python amplitudes, include=FALSE}

if r.processdata==1:
  # code to get SSEP amplitudes for analysis
  
  #Suppress console output from MNE (as this gives a lot of output)
  mne.set_log_level('ERROR')
  
  ## Begin ##
  
  #Set up a dictionary to record participants with erroneous numbers of trials. 
  errorDict = {}
  participantList = []
  
  #make zeros arrays for amplitudes and ses's to be placed in 
  amplitudes1 = np.zeros([46,4])
  #exploratory amplitudes
  amplitudes2 = np.zeros([46,4])
  subjectcount = -1
  
  #make matrix to store fourier spectrum in
  allfspec = np.empty([46,4,62,1001],dtype = complex)
  
  print('Reading subject...')
  
  for subjectno in range(1,49):
        
    subject = (f'P{subjectno}')
    
    #only analyse data if more than 32 electrodes are available    
    thrCount = meanses[subjectno-1,0:62] > thd
    if thrCount.sum() < 32:
      
      print(f'P{subjectno:02}', end = ' ')
      
      raw_fname = os.path.join(datadir, subject, f'P{subjectno}_block1_EEG.set')
      
      #increase subjectcount for each participant
      subjectcount = subjectcount+1
      
      #Read in data    
      raw = mne.io.read_raw_eeglab(raw_fname,preload=True)
      
      #get channel names
      ch_names_all = raw.ch_names
      
      #load in EEG montage
      ANT_montage = mne.channels.make_standard_montage("standard_1020")
      
      #drop initial channels, then create new list for channeles to drop per participant
      drop_channel_list_initial = ["HEOG", "VEOG", "M1", "M2"]
      drop_channel_list = []
      raw.drop_channels(drop_channel_list_initial)
      ch_names_full = raw.ch_names
      for electrode in range(len(ch_names_all) - len(drop_channel_list_initial)):
        #If means exceed threshhold or are nan, add electrode number to the
        #list for dropping 
        if meanses[subjectno-1, electrode] > thd:      
          drop_channel_list.append(electrode)
        elif math.isnan(meanses[subjectno-1, electrode]):
          drop_channel_list.append(electrode)
            
      drop_channel_list_electrodes = [electrodeDict.get(item,item) for item in drop_channel_list]
      raw.drop_channels(drop_channel_list_electrodes)
            
      raw.set_montage(ANT_montage)
            
      #Apply 50Hz notch filter
      filtered = raw.copy().notch_filter(freqs=50)
            
      #extract triggers
      events, event_id = mne.events_from_annotations(filtered)
            
      #Get electrode list
      ch_names_subj = raw.ch_names
            
      #get EOIs - if any are absent, replace with false strings
      if "F1" in ch_names_subj:
        e1 = ch_names_subj.index("F1")
      else:
        e1 = 'false'
      if "FC1" in ch_names_subj:
        e2 = ch_names_subj.index("FC1")
      else:
        e2 = 'false'
                    
      #if F1 or FC1 don't exist, then replace with existing value
      if e1 == 'false':
        e1 = e2
      if e2 == 'false':
        e2 = e1
                        
      #make indices array of EOIs
      eindices = np.array([e1,e2])
    
      #set condition triggers
      legaltriggers = [10,20,30,40]
                        
      #make variable for exracted values
      extracted_values = []
                        
      #use condition triggers as event triggers
      for trigger in legaltriggers:
        trigger_str = str(trigger)
        if trigger_str in event_id:
          extracted_values.append(event_id[trigger_str])
       
      #define event labels for each condition based on extracted values
      event_dict = {"NI": extracted_values[0],"NIT": extracted_values[1],"MS": extracted_values[2],"UV": extracted_values[3]}    
       
      #Set rejection criteria
      reject_criteria = None   #dict(eeg=200e-6)
                              
      #epoch data
      allepochs = mne.Epochs(filtered, events, event_id=event_dict, tmin=0.4, tmax=2.4, baseline=(0.4,2.4), reject=reject_criteria, preload=True)
                              
      #get trial data from epochs
      trials = allepochs.get_data()*1000000
                              
      temp = (trials[1,1,1:2001])
                              
      fspec_combined = np.empty([1001,4])
                              
      #get combined amplitude signal for each condition
      for cond in range(2,6):
        if cond==2: event_dict = {"NI": extracted_values[0]}
        if cond==3: event_dict = {"NIT": extracted_values[1]}
        if cond==4: event_dict = {"MS": extracted_values[2]}
        if cond==5: event_dict = {"UV": extracted_values[3]}
        condepochs = mne.Epochs(filtered, events, event_id=event_dict, tmin=0.4, tmax=2.4, baseline=(0.4,2.4), reject=reject_criteria, preload=True)
        trials = condepochs.get_data()*1000000
        combinedsignal = trials[0:24,eindices,0:2000]
        combinedmean = np.mean(combinedsignal,axis=1)
        trialavecombined = np.mean(combinedmean,axis=0)
        temp = np.abs(np.fft.rfft(trialavecombined[0:2000]))/2000
        fspec_combined[0:1001,cond-2] = temp
                   
        #average across all trials for scalp topographies
        trialave = np.mean(trials,axis=0)
                                
        #calculate the Fourier spectrum separately for each electrode 
        #The waveform (timecourse) for each electrode is averaged across all trials and conditions
        for n in range((len(ch_names_all) - len(drop_channel_list_initial)) - len(drop_channel_list_electrodes)):
          ch_index = ch_names_full.index(ch_names_subj[n])
          temp = np.fft.rfft(trialave[n,0:2000])/2000
          allfspec[subjectcount-1,cond-2,ch_index,0:1001] = temp
                                  
      #plot fourier spectrum 
      freqs = np.arange(0,500,0.5)   
      
      #put amplitudes into matrix for analysis - conditions are NI/NIT/MS/UV order
      amplitudes1[subjectcount,0:4] = fspec_combined[52,0:4]
  
  #reset subject count
  subjectcount = -1
  #exploratory amplitude generation
  for subjectno in range(1,49):
        
    subject = (f'P{subjectno}')
    
    #only analyse data if more than 32 electrodes are available    
    thrCount = meanses[subjectno-1,0:62] > thd
    if thrCount.sum() < 32:
      
      print(f'P{subjectno:02}', end = ' ')
      
      raw_fname = os.path.join(datadir, subject, f'P{subjectno}_block1_EEG.set')
      
      #increase subjectcount for each participant
      subjectcount = subjectcount+1
      
      #Read in data    
      raw = mne.io.read_raw_eeglab(raw_fname,preload=True)
      
      #get channel names
      ch_names_all = raw.ch_names
      
      #load in EEG montage
      ANT_montage = mne.channels.make_standard_montage("standard_1020")
      
      #drop initial channels, then create new list for channeles to drop per participant
      drop_channel_list_initial = ["HEOG", "VEOG", "M1", "M2"]
      drop_channel_list = []
      raw.drop_channels(drop_channel_list_initial)
      ch_names_full = raw.ch_names
      for electrode in range(len(ch_names_all) - len(drop_channel_list_initial)):
        #If means exceed threshhold or are nan, add electrode number to the
        #list for dropping 
        if meanses[subjectno-1, electrode] > thd:      
          drop_channel_list.append(electrode)
        elif math.isnan(meanses[subjectno-1, electrode]):
          drop_channel_list.append(electrode)
            
      drop_channel_list_electrodes = [electrodeDict.get(item,item) for item in drop_channel_list]
      raw.drop_channels(drop_channel_list_electrodes)
            
      raw.set_montage(ANT_montage)
            
      #Apply 50Hz notch filter
      filtered = raw.copy().notch_filter(freqs=50)
            
      #extract triggers
      events, event_id = mne.events_from_annotations(filtered)
            
      #Get electrode list
      ch_names_subj = raw.ch_names
            
      #get EOIs - if any are absent, replace with false strings
      if "Fpz" in ch_names_subj:
        e1 = ch_names_subj.index("Fpz")
      else:
        e1 = 'false'
      if "FCz" in ch_names_subj:
        e2 = ch_names_subj.index("FCz")
      else:
        e2 = 'false'
                    
      #if F1 or FC1 don't exist, then replace with existing value
      if e1 == 'false':
        e1 = e2
      if e2 == 'false':
        e2 = e1
                        
      #make indices array of EOIs
      eindices = np.array([e1,e2])
    
      #set condition triggers
      legaltriggers = [10,20,30,40]
                        
      #make variable for exracted values
      extracted_values = []
                        
      #use condition triggers as event triggers
      for trigger in legaltriggers:
        trigger_str = str(trigger)
        if trigger_str in event_id:
          extracted_values.append(event_id[trigger_str])
       
      #define event labels for each condition based on extracted values
      event_dict = {"NI": extracted_values[0],"NIT": extracted_values[1],"MS": extracted_values[2],"UV": extracted_values[3]}    
       
      #Set rejection criteria
      reject_criteria = None   #dict(eeg=200e-6)
                              
      #epoch data
      allepochs = mne.Epochs(filtered, events, event_id=event_dict, tmin=0.4, tmax=2.4, baseline=(0.4,2.4), reject=reject_criteria, preload=True)
                              
      #get trial data from epochs
      trials = allepochs.get_data()*1000000
                              
      temp = (trials[1,1,1:2001])
                              
      fspec_combined = np.empty([1001,4])
                              
      #get combined amplitude signal for each condition
      for cond in range(2,6):
        if cond==2: event_dict = {"NI": extracted_values[0]}
        if cond==3: event_dict = {"NIT": extracted_values[1]}
        if cond==4: event_dict = {"MS": extracted_values[2]}
        if cond==5: event_dict = {"UV": extracted_values[3]}
        condepochs = mne.Epochs(filtered, events, event_id=event_dict, tmin=0.4, tmax=2.4, baseline=(0.4,2.4), reject=reject_criteria, preload=True)
        trials = condepochs.get_data()*1000000
        combinedsignal = trials[0:24,eindices,0:2000]
        combinedmean = np.mean(combinedsignal,axis=1)
        trialavecombined = np.mean(combinedmean,axis=0)
        temp = np.abs(np.fft.rfft(trialavecombined[0:2000]))/2000
        fspec_combined[0:1001,cond-2] = temp
                   
        #average across all trials for scalp topographies
        trialave = np.mean(trials,axis=0)
                                
        #calculate the Fourier spectrum separately for each electrode 
        #The waveform (timecourse) for each electrode is averaged across all trials and conditions
        for n in range((len(ch_names_all) - len(drop_channel_list_initial)) - len(drop_channel_list_electrodes)):
          ch_index = ch_names_full.index(ch_names_subj[n])
          temp = np.fft.rfft(trialave[n,0:2000])/2000
          allfspec[subjectcount-1,cond-2,ch_index,0:1001] = temp
                                  
      #put exploratory amplitudes into matrix for analysis - conditions are NI/NIT/MS/UV order
      amplitudes2[subjectcount,0:4] = fspec_combined[52,0:4]
                                  
  np.save('local/Allfspec.npy',allfspec)
  np.save('local/amplitudes1.npy',amplitudes1)
  np.save('local/amplitudes2.npy',amplitudes2)
  np.save('local/channames.npy',ch_names_full)
                                  

```

```{r SSEPanalysis, include=FALSE}

#EEG Analysis

#install needed package
#install_miniconda()
# use_miniconda('r-reticulate')

#import numpy
np <- import('numpy')

#import data
eegdata <- np$load('local/amplitudes1.npy')
allfspec <- np$load('local/Allfspec.npy')
channames <- np$load('local/channames.npy')
#import exploratory data
eegdata_exp <- np$load('local/amplitudes2.npy')

#make eegdata dataframes
eegdata <- as.data.frame(eegdata)
eegdata_exp <- as.data.frame(eegdata_exp)

#add PID column
PID = (1:46)
eegdata_1 <- cbind(PID, eegdata)
eegdata_exp <- cbind(PID, eegdata_exp)

#make data long format
eegdata_2 <- eegdata_1 %>% pivot_longer(cols=c('V1',
                                             'V2', 
                                             'V3', 
                                             'V4'),
                                             names_to='Condition',
                                             values_to='Amplitude')

eegdata_exp2 <- eegdata_exp %>% pivot_longer(cols=c('V1',
                                             'V2', 
                                             'V3', 
                                             'V4'),
                                             names_to='Condition',
                                             values_to='Amplitude')

pdf('Figures/eegdata1.pdf', width = 12, height = 11)
#visualise data
  ggplot(eegdata_2, aes(x = Condition, y = Amplitude)) + 
  #geom_violin(trim = FALSE) + 
  #geom_violin(aes(color = Condition), trim = FALSE) + 
  geom_boxplot(width = 0.2, outlier.shape = NA, color = "cornflowerblue")+
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.4,
               alpha = 0.2) +
  ylab("SSEP Amplitude (µV)")+
  font("ylab", size = 20)+
  font("xlab", size = 20)+
  font("xy.text", size = 15)+
  scale_y_log10() +
  scale_x_discrete(labels = c('NI','NIT','MS','UV'))+
  #geom_signif(data=subjecitve_data_illusion_1,comparisons=list(c("NI.Illusion.Median","MS.Illusion.Median"),
                                                               #c("NIT.Illusion.Median","MS.Illusion.Median"),
                                                               #c("UV.Illusion.Median","MS.Illusion.Median")),
              #map_signif_level = TRUE,annotations="***",y_position = c(115,135,145))+
  scale_color_manual(values = c("cornflowerblue", "cornflowerblue","cornflowerblue", "cornflowerblue"))+
  theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),legend.position = "none", panel.background = element_blank(),axis.line = element_line(colour = "black"))
dev.off()

pdf('Figures/eegdata2.pdf', width = 12, height = 11)
#visualise data
  ggplot(eegdata_exp2, aes(x = Condition, y = Amplitude)) + 
  #geom_violin(trim = FALSE) + 
  #geom_violin(aes(color = Condition), trim = FALSE) + 
  geom_boxplot(width = 0.2, outlier.shape = NA, color = "cornflowerblue")+
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.4,
               alpha = 0.2) +
  ylab("SSEP Amplitude (µV)")+
  font("ylab", size = 20)+
  font("xlab", size = 20)+
  font("xy.text", size = 15)+
  scale_y_log10() +
  scale_x_discrete(labels = c('NI','NIT','MS','UV'))+
  #geom_signif(data=subjecitve_data_illusion_1,comparisons=list(c("NI.Illusion.Median","MS.Illusion.Median"),
                                                               #c("NIT.Illusion.Median","MS.Illusion.Median"),
                                                               #c("UV.Illusion.Median","MS.Illusion.Median")),
              #map_signif_level = TRUE,annotations="***",y_position = c(115,135,145))+
  scale_color_manual(values = c("cornflowerblue", "cornflowerblue","cornflowerblue", "cornflowerblue"))+
  theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),legend.position = "none", panel.background = element_blank(),axis.line = element_line(colour = "black"))
dev.off()

#assumption check
assumption_eeg1 <- eegdata_2 %>%
  group_by(Condition) %>%
  shapiro_test(Amplitude)

assumption_eeg2 <- eegdata_exp2 %>%
  group_by(Condition) %>%
  shapiro_test(Amplitude)

#ggqqplot(eegdata_2, "Amplitude", facet.by = "Condition")

#get medians and sds for eeg data
eegdatamsds <- group_by(eegdata_2, Condition) %>%
  summarise(
    count = n(),
    median = median(Amplitude, na.rm = TRUE),
    mean = mean(Amplitude, na.rm = TRUE),
    sd = sd(Amplitude, na.rm = TRUE)
  )

eegdatamsds2 <- group_by(eegdata_exp2, Condition) %>%
  summarise(
    count = n(),
    median = median(Amplitude, na.rm = TRUE),
    sd = sd(Amplitude, na.rm = TRUE)
  )

#run one way RMANOVA for illusion data
res.aov4 <- anova_test(data = eegdata_2, dv = Amplitude, wid = PID, within = Condition, effect.size = "pes")
get_anova_table(res.aov4)

#posthoc tests
pwc4 <- eegdata_2 %>%
pairwise_t_test(
  Amplitude ~ Condition, paired = TRUE,
  p.adjust.method = "bonferroni",
  detailed = TRUE
)
pwc4

eegMSNIes <- tes(1.7,46,46)
eegUVNIes <- tes(1.15,46,46)
eegNINITes <- tes(2.02,46,46)

#non-parametric test
res.fried_eeg1 <- eegdata_2 %>% friedman_test(Amplitude ~ Condition |PID)
effectsize_eeg1 <- eegdata_2 %>% friedman_effsize(Amplitude ~ Condition |PID)

res.fried_eeg2 <- eegdata_exp2 %>% friedman_test(Amplitude ~ Condition |PID)
effectsize_eeg2 <- eegdata_exp2 %>% friedman_effsize(Amplitude ~ Condition |PID)

#posthoc tests
nppwc_eeg1 <- eegdata_2 %>%
  wilcox_test(Amplitude ~ Condition, paired = TRUE, comparisons = list(c("V1", "V3"), c("V1", "V4"), c("V1", "V2")), p.adjust.method = "holm",
    detailed = TRUE)

nppwc_eeg1_es <- eegdata_2 %>%
  wilcox_effsize(Amplitude ~ Condition, paired = TRUE,comparisons = list(c("V1", "V3"), c("V1", "V4"), c("V1", "V2")))

nppwc2_eeg2 <- eegdata_exp2 %>%
  wilcox_test(Amplitude ~ Condition, paired = TRUE, comparisons = list(c("V1", "V3"), c("V1", "V4"), c("V1", "V2")), p.adjust.method = "holm",
    detailed = TRUE)

```

```{r SSEPplotting}

## EEG data plotting

#create figure directory
figdir <- 'Figures'

#list of condition names
titlelist <- c('NI','NIT','MS','UV')

#confirmatory analysis electrodes
targetelectrodes1 <- match(c('F1','FC1'),channames)
#exploratory analysis electrodes
targetelectrodes2 <- match(c('FCz','Fpz'),channames)

allfspec[which(allfspec==0)] <- NA

montage <- read.csv('local/montage.csv')   # read in the ANT montage
allscalps <- apply(abs(allfspec[,,,53]),c(2,3),mean,na.rm=TRUE) # average response at 26Hz

addalpha <- function(col, alpha=1){apply(sapply(col, col2rgb)/255, 2, function(x) rgb(x[1], x[2], x[3], alpha=alpha))}

# helper function to interpolate over space
v4Interp <- function(df, xo, yo, rmax = .75, gridRes = 67) {
  ## Create a function to perform Matlab's v4 interpolation.
  ## Takes as input a data-frame with columns x, y, and z (x co-ordinates, y co-ordinates, and amplitude)
  ## and variables xo and yo, the co-ordinates which will be use to create a grid for interpolation
  xo <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
  yo <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
  xy <- df$x + df$y*sqrt(as.complex(-1))
  d <- matrix(rep(xy,length(xy)),nrow = length(xy), ncol = length(xy))
  d <- abs(d - t(d))
  diag(d) <- 1
  g <- (d^2) * (log(d)-1)   # Green's function.
  diag(g) <- 0
  weights <- qr.solve(g,df$z)
  xy <- t(xy)
  outmat <- matrix(nrow = gridRes,ncol = gridRes)
  for (i in 1:gridRes){
    for (j in 1:gridRes) {
      test4 <- abs((xo[i,j] + sqrt(as.complex(-1))*yo[i,j]) - xy)
      g <- (test4^2) * (log(test4)-1)
      outmat[i,j] <- g %*% weights}}
  outDf <- data.frame(x = xo[,1],outmat)
  names(outDf)[1:length(yo[1,])+1] <- yo[1,]
  return(outDf)}

## Create data frame to be used for interpolation - the function needs columns labelled x, y, and z
rmax <- 0.55   #specify a maximum boundary for the grid
gridRes <- 100 #specify the interpolation grid resolution

#ramp2 <- colorRamp(c("black","darkblue","cornflowerblue","lightblue","white"))
ramp2 <- colorRamp(c("white","lightblue","cornflowerblue","darkblue","black"))
colmatrix2 <- rgb(ramp2(seq(0, 1, length = 101)), max = 255)

xpos <- 1:62
ypos <- 1:62
for (ch in 1:62){
  i <- match(toupper(channames[ch]),toupper(as.character(montage$Electrode)))
  xpos[ch] <- montage$X_position[i]
  ypos[ch] <- montage$Y_position[i]
}

# make scalp topography for each condition using the average data
for (cond in 1:4){

datatoplot <- allscalps[cond,]
testDat<- data.frame(x = xpos,
                     y = -ypos,
                     z = datatoplot)

#Create the interpolation grid
xo <- seq(min(-rmax, testDat$x), max(rmax, testDat$x), length = gridRes)
yo <- seq(max(rmax, testDat$y), min(-rmax, testDat$y), length = gridRes)

interpV4 <- v4Interp(testDat, xo, yo, rmax, gridRes)

zo2 <- as.matrix(interpV4[,2:ncol(interpV4)])

xo2 <- matrix(rep(xo,length(yo)),nrow = length(xo),ncol = length(yo))
yo2 <- t(matrix(rep(yo,length(xo)),nrow = length(yo),ncol = length(xo)))
outsidecircle <- sqrt(xo2^2 + yo2^2) > 0.51
zo2[outsidecircle] <- 0
zo2[zo2<0] <- 0

#make head plots
tiff(paste0(figdir,'/head1_',titlelist[cond],'.tiff'),width=400,height=400)

plotlims <- c(-rmax,rmax,-rmax,rmax)  # define the x and y limits of the plot (minx,maxx,miny,maxy)
par(pty="s")  # make axis square
plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])   # create an empty axis of the correct dimensions
image(xo,xo,zo2,col=colmatrix2,zlim=c(0,1.15),add=TRUE,useRaster=FALSE)
maskx <- c(montage$OutlineX[1:51]*2.2,montage$OutlineX[51:1])
masky <- c(montage$OutlineY[1:51]*2.2,montage$OutlineY[51:1])
polygon(maskx,masky,border=NA,col="white")
maskx <- c(montage$OutlineX[51:101]*2.2,montage$OutlineX[101:51])
masky <- c(montage$OutlineY[51:101]*2.2,montage$OutlineY[101:51])
polygon(maskx,masky,border=NA,col="white")

points(xpos[targetelectrodes1],ypos[targetelectrodes1],pch=16,col="purple",cex=1.6)

lines(montage$OutlineX,montage$OutlineY,col="black",lwd=2)
lines(montage$NoseX,montage$NoseY,col="black",lwd=2)
lines(montage$LearX,montage$LearY,col="black",lwd=2)
lines(montage$RearX,montage$RearY,col="black",lwd=2)

dev.off()

#make colour bar
tiff('Figures/colourbar.tiff', height = 600, width = 600, units="px", bg="white")
plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=c(-5,5), ylim=c(0,1))   # create an empty axis of the correct dimensions
z=matrix(1:101,nrow=1)
x=0
y=seq(0,1,len=101)
image(x,y,z,col=colmatrix2,add=TRUE,useRaster=TRUE)
dev.off()

#make exploratory headplots
tiff(paste0(figdir,'/head2_',titlelist[cond],'.tiff'),width=400,height=400)

plotlims <- c(-rmax,rmax,-rmax,rmax)  # define the x and y limits of the plot (minx,maxx,miny,maxy)
par(pty="s")  # make axis square
plot(x=NULL,y=NULL,ann=FALSE, axes=FALSE, xlim=plotlims[1:2], ylim=plotlims[3:4])   # create an empty axis of the correct dimensions
image(xo,xo,zo2,col=colmatrix2,zlim=c(0,1.15),add=TRUE,useRaster=FALSE)
maskx <- c(montage$OutlineX[1:51]*2.2,montage$OutlineX[51:1])
masky <- c(montage$OutlineY[1:51]*2.2,montage$OutlineY[51:1])
polygon(maskx,masky,border=NA,col="white")
maskx <- c(montage$OutlineX[51:101]*2.2,montage$OutlineX[101:51])
masky <- c(montage$OutlineY[51:101]*2.2,montage$OutlineY[101:51])
polygon(maskx,masky,border=NA,col="white")

points(xpos[targetelectrodes2],ypos[targetelectrodes2],pch=16,col="purple",cex=1.6)

lines(montage$OutlineX,montage$OutlineY,col="black",lwd=2)
lines(montage$NoseX,montage$NoseY,col="black",lwd=2)
lines(montage$LearX,montage$LearY,col="black",lwd=2)
lines(montage$RearX,montage$RearY,col="black",lwd=2)

dev.off()
}

#for individual plots uncomment next line
#for (subj in 1:46){

#create spectra plots
#for individual plots comment next line
pdf(paste0(figdir,"/spectrum1.pdf"), width=12, height=12)
#for individual plots uncomment next line
#pdf(paste0(figdir,"/spectrum",subj,".pdf"), width=12, height=12)
par(mfrow=c(2,2))
# plot the Fourier spectra across all electrodes
f <- seq(0,499.5,0.5)

  ticklocsx <- seq(0,50,10)
  ticklocsy <- seq(0,0.5,0.1)

meanftemp <- apply(allfspec[,,targetelectrodes1,],c(1,2,4),mean,na.rm=TRUE)
meanfspec <- apply(abs(meanftemp),c(2,3),median,na.rm=TRUE)
SEfspec <- apply(abs(meanftemp),c(2,3),sd)/sqrt(46)

for (cond in 1:4){
  
  h1 <- readTIFF(paste0(figdir,'/head1_',titlelist[cond],'.tiff'))
  e3 <- readTIFF('Figures/colourbar.tiff')

  plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(min(ticklocsx),max(ticklocsx)), ylim=c(min(ticklocsy),max(ticklocsy)))
  axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
  axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
  mtext(text = ticklocsx, side = 1, at=ticklocsx, line=0.5, cex=1.3)
  mtext(text = ticklocsy, side = 2, at=ticklocsy, line=0.2, las=1, cex=1.3)
  title(xlab='Frequency (Hz)', col.lab=rgb(0,0,0), line=2, cex.lab=2.5)
  title(ylab='Amplitude (µV)', col.lab=rgb(0,0,0), line=2.4, cex.lab=2.5)
  title(main=titlelist[cond],cex.main=2)  

  aspratio <- 90  # this is the aspect ratio of the output pdf
  imwidth <- 0.4
  xstart <- 18
  ystart <- 0.15
  rasterImage(h1,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth) 
  
  imwidth <- 0.1
  xstart <- 40
  ystart <- 0.12
  rasterImage(e3,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
  
  text(38,0.12,'0',pos=4,cex=1.8)
  text(34,0.2,'1.15',pos=4,cex=1.8)
  text(49,0.24,'Amplitude',pos=4,cex=2,srt=270)
  
  #for individual plots comment next line
polygon(f[c(3:100,100:3)],c(meanfspec[cond,3:100]+SEfspec[cond,3:100],meanfspec[cond,100:3]-SEfspec[cond,100:3]),col=addalpha('cornflowerblue',0.25),border=NA)
  #for individual plots comment next line
lines(f[3:100],meanfspec[cond,3:100],lwd=3) 
  #for individual plots uncomment next line
#lines(f[3:100],abs(meanftemp[subj,cond,3:100]),lwd=1)
# lines(c(0,50), meanfspec[1,c(53,53)],lty=2)
# lines(c(26,26),c(0,0.5),col='red')
}
dev.off()
#for individual plots uncomment next line
#}

#create exploratory spectra plots
# pdf(paste0(figdir,"/spectrum_other.pdf"), width=12, height=12)
# par(mfrow=c(2,2))
# # plot the Fourier spectra across all electrodes
# f <- seq(0,499.5,0.5)
# 
#   ticklocsx <- seq(0,50,10)
#   ticklocsy <- seq(0,0.5,0.1)
# 
# meanftemp <- apply(allfspec[,,targetelectrodes2,],c(1,2,4),mean,na.rm=TRUE)
# meanfspec <- apply(abs(meanftemp),c(2,3),median,na.rm=TRUE)
# SEfspec <- apply(abs(meanftemp),c(2,3),sd)/sqrt(46)
# 
# for (cond in 1:4){
#   
#   h1 <- readTIFF(paste0(figdir,'/head2_',titlelist[cond],'.tiff'))
#   e3 <- readTIFF('Figures/colourbar.tiff')
# 
#   plot(x=NULL,y=NULL,axes=FALSE, ann=FALSE, xlim=c(min(ticklocsx),max(ticklocsx)), ylim=c(min(ticklocsy),max(ticklocsy)))
#   axis(1, at=ticklocsx, tck=0.01, lab=F, lwd=2)     # plot tick marks (no labels)
#   axis(2, at=ticklocsy, tck=0.01, lab=F, lwd=2)
#   mtext(text = ticklocsx, side = 1, at=ticklocsx, line=0.5, cex=1.3)
#   mtext(text = ticklocsy, side = 2, at=ticklocsy, line=0.2, las=1, cex=1.3)
#   title(xlab='Frequency (Hz)', col.lab=rgb(0,0,0), line=2, cex.lab=2.5)
#   title(ylab='Amplitude (µV)', col.lab=rgb(0,0,0), line=2.4, cex.lab=2.5)
#   title(main=titlelist[cond],cex.main=2)  
# 
#   aspratio <- 90  # this is the aspect ratio of the output pdf
#   imwidth <- 0.4
#   xstart <- 18
#   ystart <- 0.15
#   rasterImage(h1,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth) 
#   
#   imwidth <- 0.1
#   xstart <- 40
#   ystart <- 0.12
#   rasterImage(e3,xstart,ystart,xstart+imwidth*aspratio,ystart+imwidth)
#   
#   text(38,0.12,'0',pos=4,cex=1.8)
#   text(34,0.2,'1.15',pos=4,cex=1.8)
#   text(49,0.24,'Amplitude',pos=4,cex=2,srt=270)
#   
# # -- polygon(f[c(3:100,100:3)],c(meanfspec[cond,3:100]+SEfspec[cond,3:100],meanfspec[cond,100:3]-SEfspec[cond,100:3]),col=addalpha('cornflowerblue',0.25),border=NA)
# 
# # - -lines(f[3:100],meanfspec[cond,3:100],lwd=3) 
# # lines(c(0,50), meanfspec[1,c(53,53)],lty=2)
# # lines(c(26,26),c(0,0.5),col='red')
# }
# dev.off()



#assess electrodes with greatest response

#turn allscalps into dataframe
allscalps2 <- as.data.frame(allscalps)

#sum the data from each condition for each electrode and create new dataframe
sumscalps <- allscalps2 %>%
  pivot_longer(cols = everything(), names_to = "Electrode", values_to = "val") %>%
  group_by(Electrode) %>%
  summarise(Total = sum(val))

#order new dataframe in ascending order to show 2 electrodes with greatest response (V2, V40 (Fpz, FCz))
sumscalps2 <- arrange(sumscalps, Total)


```

```{r subjectiveanalysis}

#load in demographic data
demographic_data <- read.csv("local/demographics.csv")

mean_age = mean(demographic_data$Age)
max_age = (max(demographic_data$Age, na.rm=TRUE))
min_age = (min(demographic_data$Age, na.rm=TRUE))
sex_table = as.data.frame(table(demographic_data$Sex))
ethnicity_table = as.data.frame(table(demographic_data$Ethnicity))

#load in handedness data
handedness_data <- read.csv("local/handedness.csv")

#make cells numeric
handedness_data[1] <- lapply(handedness_data[1], as.numeric)

#change sign from negative to positive
handedness_data[sapply(handedness_data, is.numeric)] <- handedness_data[sapply(handedness_data, is.numeric)] * -1

#find means, min and max values 
mean_handedness = mean(handedness_data$Handedness)
max_handedness = (max(handedness_data$Handedness, na.rm=TRUE))
min_handedness = (min(handedness_data$Handedness, na.rm=TRUE))

#load in subjective data
subjective_data <- read.csv("local/subjective data.csv")

#make new dataset for normalised data
subjective_data_new <- subjective_data

#subtract the control median from the illusion and disownship medians for all conditions across all participants
for (n in 1:46){
subjective_data_new[(n),4] <- subjective_data[(n),4] - subjective_data[(n),10]
subjective_data_new[(n),7] <- subjective_data[(n),7] - subjective_data[(n),10]
subjective_data_new[(n),13] <- subjective_data[(n),13] - subjective_data[(n),19]
subjective_data_new[(n),16] <- subjective_data[(n),16] - subjective_data[(n),19]
subjective_data_new[(n),22] <- subjective_data[(n),22] - subjective_data[(n),28]
subjective_data_new[(n),25] <- subjective_data[(n),25] - subjective_data[(n),28]
subjective_data_new[(n),31] <- subjective_data[(n),31] - subjective_data[(n),37]
subjective_data_new[(n),34] <- subjective_data[(n),34] - subjective_data[(n),37]
}

#illusion analysis

#keep data needed for illusion analysis
subjective_data_illusion <- subset(subjective_data_new, select = -c(NI.Illusion.1,NI.Illusion.2,NI.Disownership.1,NI.Disownership.2,NI.Disownership.Median,NI.Control.1,NI.Control.2, NI.Control.Median,
                                                                    NIT.Illusion.1,NIT.Illusion.2,NIT.Disownership.1,NIT.Disownership.2,NIT.Disownership.Median,NIT.Control.1,NIT.Control.2, NIT.Control.Median,
                                                                    MS.Illusion.1,MS.Illusion.2,MS.Disownership.1,MS.Disownership.2,MS.Disowenership.Median,MS.Control.1,MS.Control.2, MS.Control.Median,
                                                                    UV.Illusion.1,UV.Illusion.2,UV.Disownership.1,UV.Disownership.2,UV.Disownership.Median,UV.Control.1,UV.Control.2, UV.Control.Median))

#make data long format
subjecitve_data_illusion_1 <- subjective_data_illusion %>% pivot_longer(cols=c('NI.Illusion.Median',
                                                 'NIT.Illusion.Median', 
                                                 'MS.Illusion.Median', 
                                                 'UV.Illusion.Median'),
                    names_to='Condition',
                    values_to='Score')

subjecitve_data_illusion_1 <- subjecitve_data_illusion_1 %>%
  mutate(Condition=factor(Condition,levels=c("NI.Illusion.Median", "NIT.Illusion.Median", "MS.Illusion.Median", "UV.Illusion.Median")))

pdf('Figures/illusiondata.pdf', width = 12, height = 12)
#visualise data
  ggplot(subjecitve_data_illusion_1, aes(x = Condition, y = Score)) + 
  #geom_violin(trim = FALSE) + 
  #geom_violin(aes(color = Condition), trim = FALSE) + 
  geom_boxplot(width = 0.2, outlier.shape = NA, color = "cornflowerblue")+
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.3,
               alpha = 0.2) +
  ylab("Illusion Score")+
  ylim(-100,138) +
  font("ylab", size = 20)+
  font("xlab", size = 20)+
  font("xy.text", size = 15)+
  scale_x_discrete(labels = c('NI','NIT','MS','UV'))+
  geom_signif(data=subjecitve_data_illusion_1,comparisons=list(c("NI.Illusion.Median","MS.Illusion.Median"),
                                                               c("NIT.Illusion.Median","MS.Illusion.Median"),
                                                               c("UV.Illusion.Median","MS.Illusion.Median")),
              map_signif_level = TRUE,annotations="***",y_position = c(105,120,129))+
  scale_color_manual(values = c("cornflowerblue", "cornflowerblue","cornflowerblue", "cornflowerblue"))+
  theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),legend.position = "none", panel.background = element_blank(),axis.line = element_line(colour = "black"))
dev.off()

#assumption check
subjecitve_data_illusion_1 %>%
  group_by(Condition) %>%
  shapiro_test(Score)

#ggqqplot(subjecitve_data_illusion_1, "Score", facet.by = "Condition")

#run one way RMANOVA for illusion data
res.aov1 <- anova_test(data = subjecitve_data_illusion_1, dv = Score, wid = PID, within = Condition,effect.size = "pes")
get_anova_table(res.aov1)

#get medians and sds for illusion data
illusionmsds <- group_by(subjecitve_data_illusion_1, Condition) %>%
  summarise(
    count = n(),
    median = median(Score, na.rm = TRUE),
    mean = mean(Score, na.rm = TRUE),
    sd = sd(Score, na.rm = TRUE)
  )
illusionmsds

#posthoc tests
pwc1 <- subjecitve_data_illusion_1 %>%
  pairwise_t_test(
    Score ~ Condition, paired = TRUE,
    p.adjust.method = "bonferroni",
    detailed = TRUE
  )
pwc1

MSNIes <- tes(-5.67,46,46)
MSNITes <- tes(-5.61,46,46)

#non-parametric tests
res.fried_illusion <- subjecitve_data_illusion_1 %>% friedman_test(Score ~ Condition |PID)
effectsize_illusion <- subjecitve_data_illusion_1 %>% friedman_effsize(Score ~ Condition |PID)

#posthoc tests
nppwc_illusion <- subjecitve_data_illusion_1 %>%
  wilcox_test(Score ~ Condition, paired = TRUE, p.adjust.method = "holm",
    detailed = TRUE)

nppwc_illusion_es <- subjecitve_data_illusion_1 %>%
  wilcox_effsize(Score ~ Condition, paired = TRUE)

#disownership analysis

#keep data needed for disownership analysis
subjective_data_disownership <- subset(subjective_data_new, select = -c(NI.Illusion.1,NI.Illusion.2,NI.Disownership.1,NI.Disownership.2,NI.Illusion.Median,NI.Control.1,NI.Control.2, NI.Control.Median,
                                                                    NIT.Illusion.1,NIT.Illusion.2,NIT.Disownership.1,NIT.Disownership.2,NIT.Illusion.Median,NIT.Control.1,NIT.Control.2, NIT.Control.Median,
                                                                    MS.Illusion.1,MS.Illusion.2,MS.Disownership.1,MS.Disownership.2,MS.Illusion.Median,MS.Control.1,MS.Control.2, MS.Control.Median,
                                                                    UV.Illusion.1,UV.Illusion.2,UV.Disownership.1,UV.Disownership.2,UV.Illusion.Median,UV.Control.1,UV.Control.2, UV.Control.Median))

#make data long format
subjecitve_data_disownership_1 <- subjective_data_disownership %>% pivot_longer(cols=c('NI.Disownership.Median',
                                                                               'NIT.Disownership.Median', 
                                                                               'MS.Disowenership.Median', 
                                                                               'UV.Disownership.Median'),
                                                                        names_to='Condition',
                                                                        values_to='Score')

subjecitve_data_disownership_1 <- subjecitve_data_disownership_1 %>%
  mutate(Condition=factor(Condition,levels=c("NI.Disownership.Median", "NIT.Disownership.Median", "MS.Disowenership.Median", "UV.Disownership.Median")))

pdf('Figures/disownershipdata.pdf', width = 12, height = 11)
#visualise data
  ggplot(subjecitve_data_disownership_1, aes(x = Condition, y = Score)) + 
  #geom_violin(trim = FALSE) + 
  #geom_violin(aes(color = Condition), trim = FALSE) + 
  geom_boxplot(width = 0.2, outlier.shape = NA, color="cornflowerblue")+
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.25,
               alpha = 0.2) +
  ylab("Disownerhsip Score")+
  ylim(-100,138) +
  font("ylab", size = 20)+
  font("xlab", size = 20)+
  font("xy.text", size = 15)+
  scale_x_discrete(labels = c('NI','NIT','MS','UV'))+
  geom_signif(data=subjecitve_data_disownership_1,comparisons=list(c("NI.Disownership.Median","UV.Disownership.Median"),
                                                               c("NIT.Disownership.Median","UV.Disownership.Median"),
                                                               c("MS.Disowenership.Median","UV.Disownership.Median")),
              map_signif_level = TRUE,annotations=c("*","***","*"),y_position = c(105,120,129))+
  scale_color_manual(values = c("cornflowerblue", "cornflowerblue","cornflowerblue", "cornflowerblue"))+
  theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),legend.position = "none", panel.background = element_blank(),axis.line = element_line(colour = "black"))
dev.off()

#assumption check
subjecitve_data_disownership_1 %>%
  group_by(Condition) %>%
  shapiro_test(Score)

#ggqqplot(subjecitve_data_disownership_1, "Score", facet.by = "Condition")

#run one way RMANOVA for illusion data
#res.aov2 <- anova_test(data = subjecitve_data_disownership_1, dv = Score, wid = PID, within = Condition)
#get_anova_table(res.aov2)

#get medians and sds for disownership data
disownershipmsds <- group_by(subjecitve_data_disownership_1, Condition) %>%
  summarise(
    count = n(),
    median = median(Score, na.rm = TRUE),
    sd = sd(Score, na.rm = TRUE)
  )
disownershipmsds

#posthoc tests
# pwc2 <- subjecitve_data_disownership_1 %>%
#   pairwise_t_test(
#     Score ~ Condition, paired = TRUE,
#     p.adjust.method = "bonferroni",
#     detailed = TRUE
#   )

#non-parametric tests
res.fried_disownership <- subjecitve_data_disownership_1 %>% friedman_test(Score ~ Condition |PID)
effectsize_disownership <- subjecitve_data_disownership_1 %>% friedman_effsize(Score ~ Condition |PID)

#posthoc tests
nppwc_disownership <- subjecitve_data_disownership_1 %>%
  wilcox_test(Score ~ Condition, paired = TRUE, p.adjust.method = "holm",
    detailed = TRUE)

nppwc_disownership_es <- subjecitve_data_disownership_1 %>%
  wilcox_effsize(Score ~ Condition, paired = TRUE)

#control analysis

#keep data needed for control analysis
subjective_data_control <- subset(subjective_data_new, select = -c(NI.Illusion.1,NI.Illusion.2,NI.Disownership.1,NI.Disownership.2,NI.Illusion.Median,NI.Control.1,NI.Control.2, NI.Disownership.Median,
                                                                        NIT.Illusion.1,NIT.Illusion.2,NIT.Disownership.1,NIT.Disownership.2,NIT.Illusion.Median,NIT.Control.1,NIT.Control.2, NIT.Disownership.Median,
                                                                        MS.Illusion.1,MS.Illusion.2,MS.Disownership.1,MS.Disownership.2,MS.Illusion.Median,MS.Control.1,MS.Control.2, MS.Disowenership.Median,
                                                                        UV.Illusion.1,UV.Illusion.2,UV.Disownership.1,UV.Disownership.2,UV.Illusion.Median,UV.Control.1,UV.Control.2, UV.Disownership.Median))

#make data long format
subjecitve_data_control_1 <- subjective_data_control %>% pivot_longer(cols=c('NI.Control.Median',
                                                                                       'NIT.Control.Median', 
                                                                                       'MS.Control.Median', 
                                                                                       'UV.Control.Median'),
                                                                                names_to='Condition',
                                                                                values_to='Score')

subjecitve_data_control_1 <- subjecitve_data_control_1 %>%
  mutate(Condition=factor(Condition,levels=c("NI.Control.Median", "NIT.Control.Median", "MS.Control.Median", "UV.Control.Median")))

pdf('Figures/controldata.pdf', width = 12, height = 11)
#visualise data
  ggplot(subjecitve_data_control_1, aes(x = Condition, y = Score)) + 
  #geom_violin(trim = FALSE) + 
  #geom_violin(aes(color = Condition), trim = FALSE) + 
  geom_boxplot(width = 0.2, outlier.shape = NA, color="cornflowerblue")+
  stat_summary(fun.y=mean, geom="point", shape=20, size=5, color="black", fill="black") +
  geom_dotplot(binaxis = "y",
               stackdir = "center",
               dotsize = 0.25,
               alpha = 0.2) +
  ylab("Control Score")+
  font("ylab", size = 20)+
  font("xlab", size = 20)+
  font("xy.text", size = 15)+
  scale_x_discrete(labels = c('NI','NIT','MS','UV'))+
  scale_color_manual(values = c("cornflowerblue", "cornflowerblue","cornflowerblue", "cornflowerblue"))+
  theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),legend.position = "none", panel.background = element_blank(),axis.line = element_line(colour = "black"))
dev.off()

#assumption check
subjecitve_data_control_1 %>%
  group_by(Condition) %>%
  shapiro_test(Score)

#ggqqplot(subjecitve_data_control_1, "Score", facet.by = "Condition")

#run one way RMANOVA for illusion data
#res.aov3 <- anova_test(data = subjecitve_data_control_1, dv = Score, wid = PID, within = Condition)
#get_anova_table(res.aov3)

#get medians and sds for control data
controlmsds <- group_by(subjecitve_data_control_1, Condition) %>%
  summarise(
    count = n(),
    median = median(Score, na.rm = TRUE),
    sd = sd(Score, na.rm = TRUE)
  )

#posthoc tests
#pwc3 <- subjecitve_data_control_1 %>%
  #pairwise_t_test(
    #Score ~ Condition, paired = TRUE,
    #p.adjust.method = "bonferroni"
  #)
#pwc3

#non-parametric tests
kruskall.wallis <- kruskal.test(Score ~ Condition, data = subjecitve_data_control_1)
#res.fried_control <- subjecitve_data_control_1 %>% friedman_test(Score ~ Condition |PID)
#effectsize_control <- subjecitve_data_control_1 %>% friedman_effsize(Score ~ Condition |PID)

#posthoc tests
# nppwc_control <- subjecitve_data_control_1 %>%
#   wilcox_test(Score ~ Condition, paired = TRUE, p.adjust.method = "bonferroni",
#     detailed = TRUE)

nppwc_controlD <- dunnTest(Score ~ Condition,
         data=subjecitve_data_control_1,
         method="bonferroni")



#exploratory correlation analysis

correlation_data <- cbind(eegdata_2[3],subjecitve_data_illusion_1[1:3])


pdf('Figures/correlationdata.pdf', width = 12, height = 11)
  ggscatter(correlation_data, x = "Score", y = "Amplitude", 
          facet.by = "Condition",
          panel.labs = list( Condition=c( "NI","NIT","MS","UV") ),
          add = "reg.line", conf.int = TRUE, 
          cor.coef = TRUE, cor.method = "spearman",
          cor.coef.size = 8,
          xlab = "Subjecitve Illusion Score", ylab = "SSEP Amplitude (µV)") +
    theme(axis.text.x = element_text(size = 20), axis.text.y = element_text(size = 20),axis.title.x = element_text(size = 20), axis.title.y = element_text(size = 20),text = element_text(size = 20))
          
dev.off()

 
```



# Abstract

Resizing illusions, delivered using augmented reality, resize a body part through either stretching or shrinking manipulations. These resizing illusions have been investigated in visuotactile, visual-only, and visuo-auditory presentations. However, the neural underpinnings of these resizing illusions remain undefined. This study sought to understand the neural mechanisms behind these illusions by using somatosensory steady state evoked potentials in addition to subjective self-report questionnaires, to enhance knowledge of what drives the subjective embodiment during resizing illusions. Since these Illusions have been shown to provide analgesic effects for individuals with chronic pain conditions, this study also aimed to provide an empirical basis for future investigations in chronic pain samples undergoing resizing illusions. Confirmatory analyses (N = 46) demonstrated significant differences in subjective experience between non-illusion and multisensory illusion conditions, and electroencephalography (EEG) data measuring somatosensory steady state evoked potential (SSEP) response across electrodes of interest (F1 & FC1) to 26Hz stimulation of the resized digit showed no significant effects of condition. However, further exploratory non-parametric SSEP analyses revealed a significant effect of condition, with reduced amplitudes in illusion conditions compared to non-illusion conditions, but no significant differences in exploratory post hoc tests. While confirmatory findings demonstrated no clear effect of resizing illusions on SSEP amplitudes for participants without chronic pain, exploratory findings could be interpreted as a potential “sharpening” of neural representations resulting from illusory stretching. These findings therefore provide a basis for investigations of comparable subjective and steady state illusion responses in a chronic pain population, who are thought to have more diffuse neural representations of their affected body parts.

# Introduction

Illusory finger stretching is a form of multisensory illusion, specifically a resizing illusion, which alters the subjective perceptual experience of the size of one’s finger. Resizing illusions, through changing the way in which a body part is perceived, exploit principles of multisensory integration to elicit modulations in the perceived size and shape of the body [@preston2011a; @preston2020a; @stanton2018a]. Resizing illusions are based on the rubber hand illusion, in which touch is delivered to a visible fake hand at the same time and in the same place that touch is delivered to the hidden real hand. This manipulation elicits feelings of ownership over the fake hand through the integration of multisensory (tactile and visual) inputs highlighting the apparent malleability of bodily self [@botvinick1998a]. Multisensory resizing illusions typically involve both tactile and visual inputs to the participant and can be delivered via an augmented reality system or through magnifying optics. Recent studies have also shown resizing illusions to be effectively administered through visual only, and visuo-auditory manipulations [@schaefer2007a; @tajadura-jim2017a]. However, multisensory visuotactile manipulations are reported as the most effective at inducing a strong experience of the illusion within an augmented reality system [@hansford2023a]. 

The augmented reality system used to deliver these resizing illusions presents real-time video capture of the hand, from the same position and perspective as if the hand were being viewed directly [@preston2011a]. Having real time presentation of the hand is important to create an experience as close to real life as possible, since previous work has highlighted that the strength of emobodiment can be decreased when presented in less human-like set ups (D'Alonzo et al., 2019). This augmented reality set up allows the experimenter to deliver tactile manipulations, such as gently pulling or pushing the hand/finger, whilst the participant views their hand/finger either stretching or shrinking in the augmented image. Newport, Pearce and Preston (2010) found strong embodiment using a synchronous multisensory visuotactile illusion, which was replicated in our pilot data using the same experimental set up as the current study. The pilot data showed, although not significant, a numerically greater illusory experience during synchronous visuotactile manipulations compared to asynchronous (mismatching visuotactile manipulation) control conditions (Appendix A) for illusory finger resizing. When comparing multisensory visuotactile resizing illusions to unimodal visual resizing illusions, our recent work [@hansford2023a] shows that multisensory illusions elicit significantly greater illusory experience compared to non-illusion and unimodal visual illusion conditions in healthy participants. We also showed, in exploratory analysis, that a subset of participants who experienced an illusion in the unimodal visual condition reported a stronger illusory experience in this condition than in an incongruent (mismatching visual and tactile inputs) control condition. Furthermore, we have demonstrated that a visuo-auditory presentation of the finger resizing illusion, using non-naturalistic auditory input, provides a stronger illusory experience than a visual only presentation, but this does not surpass the illusion strength given by a visuo-tactile illusion [@hansford2023b]. 

Neuroimaging has previously been used in healthy populations experiencing resizing illusions, whereby modulation of the primary somatosensory cortex has been found using neuromagnetic source imaging during visual only resizing illusions of the arm [@schaefer2007a]. Briefly, the more the subjects felt the subjective experience of an elongated arm, the more the cortical distance between the first and fifth digit decreased, showing the topographical representation of the somatosensory cortex being modulated by perceived location of a stimulus. Specifically looking at stretching multisensory visuotactile illusions, which as mentioned are those that elicit the greatest illusion strength in a majority of participants, recent research suggests that these illusions impact the neural representations of the body and reflect early-stage multimodal stimulus integration through modulation of gamma band activity [@kanayama2021a]. We have recently also investigated this illusion in healthy participants using electroencephalography (EEG) and have found support for this previous research, finding significant increases in gamma band power, likely reflecting multimodal stimulus integration, in multisensory visuotactile compared to unimodal visual conditions during illusory resizing of a finger [@hansford2023a]. Previous research using rubber hand illusions found this multisensory integration effect in early-stage gamma band increases [@kanayama2021a], whilst our recent findings show a later stage of multimodal stimulus integration when using illusory finger resizing manipulations [@hansford2023a]. 

Looking specifically at research into somatosensory cortex modulation using steady-state evoked potentials (hereafter referred to as SSEPs), low-level somatosensory responses have been induced directly using vibrations of a known frequency applied to a body part. These generate a frequency-locked SSEP detectable at the scalp using EEG [@snyder1992a; @tobimatsu1999a], and are an index of the cortical response to a stimulus. This paradigm has been used with other sensory modalities to better understand the neural mechanisms underlying multisensory integration, with findings showing that presentation of temporally congruent auditory and visual stimuli significantly enhances the magnitude and inter-trial phase coherence of auditory and visual steady-state responses [@nozaradan2012a]. Research has also found evidence of enhanced steady-state responses for within-modality stimulation of auditory and visual stimuli in isolation [@giani2012a], complementing Nozaradan et al.’s findings regarding visuo-auditory combination. Research using vibrotactile stimulation has found increases in steady-state response magnitude corresponding with the amplitude modulation rate of stimulation [@colon2012a; @rees1986a] suggesting an entrainment of oscillatory activity to temporal features of sensory stimulation [@timora2018a]. Given these findings, we anticipate that SSEPs might change during finger resizing illusions, due to the multisensory manipulations present, to give a potential index of changes in neural representations during the illusion. 

Several studies have investigated the analgesic effect of these resizing illusions, as they have been shown to reduce chronic pain in conditions such as osteoarthritis [@preston2011a; @preston2020a; @stanton2018a], chronic back pain [@diers2013a], and complex regional pain syndrome [@moseley2008a]. However, the understanding of how these illusions reduce pain is still undetermined. It has been suggested chronic pain involves cortical misrepresentations of the size of the affected body part [@boesch2016a], however, it is unknown if resizing illusions affect this cortical misrepresentation, and if this is therefore what causes the reduction in pain. At the time of experimental testing, no study has yet used neuroimaging with a chronic pain population to determine the cortical activity correlated with this illusory analgesia. However, importantly, there has also not been research conducted using SSEPs in participants without chronic pain, to understand what the cortical representations of these resizing illusions are like without the impact of a chronic pain condition. Therefore, the aim of this study is to examine potential changes in the somatosensory cortex during illusory finger resizing in participants without chronic pain, using vibrotactile SSEPs, to use as a basis for later investigations in a sample of chronic pain participants. If we can identify a link between illusory resizing and somatosensory cortex changes, this will enhance our understanding of what is happening in the brain during these illusions and will act as a reference for comparison with neural representations in individuals with chronic pain conditions. 

Using different sensory manipulations of finger resizing illusions, in addition to using an electromagnetic solenoid stimulator, this study aimed to investigate subjective illusory experience and somatosensory SSEP responses in participants without chronic pain, to better understand the experience of body ownership illusions from subjective experience and cortical representation perspectives. To test this, different finger resizing illusions consisting of multisensory (visuotactile) stretching (MS), unimodal-visual stretching (UV), a non-illusion control condition without tactile input (NI), and a non-illusion control condition with tactile input (NIT) were used to assess alternate aspects of illusory resizing manipulations and their related effects on somatosensory SSEP response. The inclusion of two control conditions (NI, NIT) was to assess whether localisation of cortical representations arise from resizing manipulations to the finger, or from tactile input given to the finger. The first hypothesis, acting as a positive control (1), was that there will be a greater illusory experience, measured via a subjective illusory experience questionnaire, in the (1a) MS condition compared to the NI condition and in the (1b) MS condition compared to the NIT condition. The main experimental hypothesis for this study was that (2) there will be a significant difference in somatosensory SSEP response across the electrodes of interest (F1 & FC1, see Appendix A Pilot Data) when comparing across all conditions.  Subsequent hypotheses were that there would be significant differences in SSEP response when comparing (2a) the MS condition to the NI condition, when comparing (2b) the UV condition to the NI condition, but (2c) that there would be no significant difference when comparing the NIT condition to the NI condition. A visual schematic of the hypotheses can be seen in Appendix B. 

# Methods

## Preregistration

This study was preregistered as a stage 1 registered report which was given in-principal acceptance (IPA) by PCI-RR and be seen at the following OSF page: https://osf.io/pfksu/ . Due to the exploratory nature of the study and thereby the need for some slight methodological deviations, this study was withdrawn as a registered report during stage 2 revisions. All data and code to reproduce the analyses and manuscript for this study can be found at the following OSF page:  https://osf.io/yhz6j/. 

## Deviations from Preregistration

-	During IPA there was an artefact from a previous round of revisions stating that if a participant needed either of the electrodes of interest removed due to noise, that the participant’s whole dataset would be removed. This should have stated that a participant’s dataset would only be removed if both electrodes of interest needed removal, otherwise analyses would be run using the remaining electrode of interest. The latter was the approach taken with SSEP data and analyses. 

-	2.	It was preregistered that parametric analyses would be run to assess all hypotheses; however, the data did not meet all assumptions for parametric tests and therefore non-parametric tests were run instead, following standard statistical practice. 

## Sample Size

Overall, based on the power analyses in section 2.7, a total sample size of 46 participants were tested. This sample size adheres to the higher end of sample size estimates (Hypothesis 2 (2.7.2) showing 46 participants needed for post hoc tests 2a – 2c). 

## Participants

Ethical approval for this research was gained from the Department of Psychology, University of York (ethics application code 950), in line with the Declaration of Helsinki. All participants gave informed written consent prior to the start of any experimental set up, and participants were instructed that they could withdraw their participation at any time during or after completion of the experiment. 46 participants were tested, with the participant’s manipulated finger being randomly split between use of either the index or middle finger. However, 2 participant’s data needed removal (>50% of electrodes requiring removal), and therefore 2 additional participants were tested to account for this missing data, both using the index finger as the manipulated digit, resulting in a final sample size of 46 participants (37 Female, 8 Male, 1 Prefer not say; Mean age = 20.3 years, age range = 18.3 – 32.7 years; 32 White, 11 Asian or Asian British, 3 Mixed or Multiple Ethnic Groups; Sample population = students at the University of York). 23 participants were tested using their index finger, the other half using their middle finger. 

### Sample inclusion / exclusion criteria:

Inclusion and exclusion criteria were determined using self-report responses relating to each item listed below:

-	Inclusion Criteria: Right-handed, 18 years of age or over, no older than 75 years of age (include those aged 75 years).

-	Exclusion Criteria: Prior theoreticl knowledge, experience or informed expectations about the research (other than given within the participant information sheet), a history of developmental, neurological or psychiatric disorders, history of drug or alcohol abuse, history of sleep disorders, history of epilepsy, having visual abnormalities that cannot be corrected optically (i.e. with glasses), or being under 18 years of age, or over 75 years of age. A history of chronic pain conditions, operations or procedures that could damage peripheral nerve pathways in the hands, current experiences of pain or more than 4 hours of consistent pain experienced in the preceding week.

Raw data exclusion criteria:

-	Less than 100% of the experiment completed by a participant, more than 50% of electrodes for a single participant requiring removal from EEG data, or if both electrodes F1 and FC1 (electrodes of interest) required removal. More information about data removal can be found in section 2.6 Preprocessing Steps. 

## Experimental Procedure

All participants completed a demographic survey, asking their age, ethnicity, and sex, and were asked to complete the revised Waterloo Handedness Questionnaire (WHQr) [@elias1998a]. The WHQr self-reported handedness questionnaire consists of 36 questions. The questions are answered on a 5-level Likert scale to determine the degree of preferred hand use, with right always being +2, right usually being +1, equal use being 0, left usually being -1, and left always being -2. The sum of the total WHQr score was then used to categorise respondents as left-handed (score of -24 or lower), mixed handed (score of -23 to +23), or right-handed (score of +24 or higher). Only participants who were categorised as right-handed continued participation. Mean handedness score across participants was +57.91 (range = +29 to +71). 

Participants were then set up with an appropriately sized 64-channel EEG cap with electrodes arranged according to the 10/20 system. The experimenter used conductive gel to make a conductive bridge between the electrodes and the scalp to attempt to obtain impedance levels of <10kΩ per electrode. Data were collected using an ANT Neuroscan system, sampling at 1kHz. The whole head average was used as a reference.

::: {#fig-ar}

![](Figures/Augmented Reality System.png)

Schematic of Augmented Reality System with Tactile Stimulator.
:::


Participants were then seated behind the augmented reality system (Figure 1) and instructed to place their hand onto the black felt fabric within the augmented reality system. Within the self-built system there was a 1920 x 1080-pixel Spedal Webcam Wide Angle Camera at the edge of the black felt on the side the participant sits, away from the participant’s view. 26cms above the felt base, there was a mirror, which was placed 26cms below a screen with a resolution of 1920 x 1200 pixels, with a width of 52cms and a height of 32cms. The thickness of section on which the mirror sat was 2cms. This screen was 54cms from the base of the system, and the base of the system was 82cms from the ground. Participants were instructed to place either their right index or middle finger outstretched onto the felt. The decision of whether the participant used their index or middle finger was pseudo randomised (to give equal representation of each finger) via MATLAB prior to any participants taking part. There were two white dots for each hand on the felt and participants were instructed to place their hand between these two dots. Participants were instructed to view their hand’s image in the mirror (whilst the real hand was hidden from view) throughout the experiment. The camera placed underneath the mirror on the felt base was used to deliver a live feed video of the participant’s hands to the computer screen at the top of the augmented reality system, which showed in the mirror reflection to the participants. There was a delay of 170ms in the video processing pipeline from the camera image to the augmented video image.

Participants underwent 4 conditions: multisensory stretching (MS), unimodal-visual stretching (UV), a non-illusion control condition without tactile input (NI), and a non-illusion control condition with tactile input (NIT). There was vibrotactile stimulation to the finger in all conditions, but only tactile input of the researcher touching the participants finger in the MS and NIT conditions. Each trial lasted 2.4 seconds for the manipulation phase, where the finger was stretched by 60 pixels (2.1 centimetres) in UV and MS conditions, followed by a further 2.4 second habituation phase in which participants could view and move their (augmented) finger, whilst they keep the rest of their hand still, before the screen went dark, indicating that the next trial could start. The MS condition consisted of the researcher touching and pulling the participant’s finger as the participant viewed their finger stretching in a congruent manner. The UV condition consisted of the participants viewing their finger stretch without any experimenter manipulation. The NI condition provided no visual or touching tactile manipulations to the finger, the image of their finger was visible and unchanged throughout. The NIT control condition involved no visual input of the finger stretching, again the image of their finger was visible but unchanged. Additionally, this condition included tactile input of the experimenter’s hand touching the participant’s finger, but without pulling. Visualisation of all conditions can be seen in Figure 2.

::: {#fig-cond}

![](Figures/Conditions.png)

Infographic of Experimental Conditions. MS = Multisensory Stretching, UV = Unimodal Visual Stretching, NIT = Non-Illusion Tactile, NI = Non-Illusion. During the manipulation phase (2.4 seconds) the visual image of the finger is stretched in the MS and UV conditions, and/or the experimenter provides tactile input (touch) in the MS and NIT conditions. The tactile input in the MS condition is accompanied by pulling.  During the habituation phase (2.4 seconds) participants are free to move their finger. The arrow denotes the direction of the experimenter’s action. The vibrotactile stimulator is depicted on the finger in each phase of the experiment as vibrations are presented throughout.
:::

The experimenter was seated opposite the participant, the other side of the augmented reality machine and touched the digit during MS and NIT conditions by holding onto the distal interphalangeal joint and gently touching (NIT) or pulling (MS) the finger whilst the participant kept their hand in place. Conditions were delivered across 4 blocks, with each block consisting of 24 trials of the same experimental condition, totalling 96 trials over all 4 blocks. The ordering of the blocks was randomised for each participant to prevent ordering effects. The experiment was programmed in, and the conditions randomised using MATLAB R2017a and the experimenter was informed of whether to pull the finger or to touch the finger via an indicative box displayed on the screen out of the participant’s view. If the box was blue, this indicated a need to pull the finger, if it was white it indicated a need to touch the finger, if there was no box displayed then this indicated no tactile manipulation from the experimenter. The researcher used a button press to trigger the start of the manipulation, and started pulling the finger, when needed, synchronously within the 2.4 second manipulation phase. If the experimenter were to forget to pull the finger on a multisensory condition, or mistakenly pulled the finger in a control trial, then this would noted during the experiment, and that trial would be removed from analysis. Fortunately, no trials needed removal due to experimenter error. Vibrations were delivered to the participant’s finger in all conditions using a miniature electromagnetic solenoid stimulator (Dancer Design Tactor; diameter 1.8mm) emitting vibrations produced by sending amplified 26Hz sine wave sound files, with stimulus intensity controlled by an amplifier (Dancer Design TactAmp). The tactor was driven at 50% of the maximum (i.e. a peak input voltage of 3V) using a 26Hz sine-wave, and delivered a peak force of 0.18N. The electromagnetic solenoid stimulator was attached to the participant’s finger that was outstretched to receive the manipulations using clear medical tape, between the knuckle and the first finger joint, and gave continuous stimulation for the duration of each trial. Participants were encouraged to take a break between each of the blocks to stretch their hand. EEG was recorded throughout as a continuous recording with conditions denoted by numbered 8-bit digital at the start of each trial (USB-TTL Module, Black Box Toolkit Ltd.). 

Finally, at the end of each block, the participant was asked to complete the subjective illusory experience questionnaire regarding a condition presented in a given block using a Samsung Galaxy Tab A6 tablet via a questionnaire on Qualtrics (Qualtrics, Provo, UT). The questionnaire consisted of six questions relating to the trials the participant had just experienced. Two statements related to illusory experience: “It felt like my finger was really stretching” / “It felt like the finger I saw was part of my body”, two related to disownership: “It felt like the finger I saw no longer belonged to me” / “It felt like the finger I saw was no longer part of my body”, and two were control questions: “It felt as if my finger had disappeared” / “It felt as if I might have had an extra finger” (all questions were directed towards the participants manipulated finger). Control questions were included to create an index for the illusion and disownership questions (more detail can be found in section 2.6 - Preprocessing steps), whilst disownership questions were included to assess if the potential experience from the illusions resulted from a disownership of the body part, or from subjective embodiment of the body part [@mccabe2011a]. A visual analogue scale from 0 – 100 was used for each statement, with 0 being strongly disagree, 50 being neutral and 100 being strongly agree. Control questions were included to create an index for the illusion and disownership questions (more detail can be found in section 2.6 Preprocessing steps), whilst disownership questions were included to assess if the potential experience from the illusions resulted from a disownership of the body part, or from subjective embodiment of the body part (McCabe, 2011). Our previous work (Hansford et al., 2024) has found that this questionnaire can produce results in line with more objective measures of proprioceptive drift and ruler judgement tasks and therefore can confidently be used to assess illusory experience. 

Data collection was terminated when the full sample of participants had been tested. If a participant completed <100% of the experiment or if over 50% of electrodes needed removal, or if both electrode F1 and FC1 needed removal, then their data was not be included, and additional participants were recruited to replace any lost data.

## Preprocessing Steps

EEG data were first converted using MATLAB and EEGlab from the ANT EEprobe .cnt format to EEGlab .set format. All subsequent analysis was then be conducted using the MNE-Python toolbox (Gramfort et al., 2013). A 50Hz notch filter was first applied to the raw EEG data for all electrodes, followed by calculation of the standard error across time for each electrode for each participant [@luck2021a]. Across the standard errors for all participants, the 5% of electrodes which showed the largest standard errors were used to create a standard error threshold. Any electrode with a standard error above this threshold, or with a value of 0, was deined as noisy and was removed from analysis. Where a participant had over 50% of their electrodes over the standard error threshold or with a value of 0, or if the electrodes requiring removal included either electrodes F1 or FC1 (electrodes of interest), then their data was removed. Primary analysis of the remaining EEG data then involved averaging the signal across the electrodes of interest (or using just electrode F1 or FC1 in case of electrode removal), and calculating the Fourier transform for each trial per participant. These amplitudes were then averaged across trials per condition to give overall results for each participant per condition. Statistical comparisons were then performed on the Fourier amplitudes at the stimulation frequency (26Hz), across conditions and participants. No additional filtering or denoising steps were applied to the EEG data, in line with Figueira et al.’s (2022) report that only a Fourier transform is typically needed for this type of EEG data.

Regarding questionnaire data, scores for both illusion experience questions were combined to give median scores, along with both disownership questions and both control questions, resulting in 3 median scores per condition per participant. The median control scores were used to create an index of the illusion and disownership scores by subtracting the median control score from the median illusion and median disownership scores, in line with previous research doing similarly [@matsumiya2021a; @kilteni2017a; @kalckert2012a]. The normalised (control indexed) data were used for analyses, with a new scale from -100 to +100 with 100 indicating strongly agree, 50 indicating a neutral opinion, and scores below 0 indicating strongly disagree with the statements on the questionnaire. 50 was maintained as a neutral opinion so that the normalised data still adhered to the thresholds that the participants were presented with during the experiment. 

All planned analyses can be seen within the stage 1 IPA report at the following OSF page: https://osf.io/pfksu/. 

## Power analysis

### Hypothesis 1 (Positive Control)

Effect sizes were determined by research from Hansford et al. (2023a) using the subjective illusory experience questionnaire and comparing MS, UV, and incongruent finger-based resizing illusions to control conditions with no illusory resizing, using the same finger stretching illusions and the same equipment (n = 48), which show an effect size of $\eta^2$ = .33 (converted to Cohen’s f  = .70 and Cohen’s d = 1.4). Additional effect size information comes from a visual capture study (n = 80) using a subjective embodiment questionnaire and visual and tactile manipulations to a mannequin body (Carey et al., 2019), showing an effect size of r = .64 (converted to Cohen’s f  = .83) when comparing embodiment scores from the questionnaire against control scores. An effect size of f = .70 was used for hypothesis 1 to adhere to the lower end of previous effect sizes. 

Hypothesis 1: A priori power analysis using G\*Power for the smallest effect size of interest (f = .70) showed that for a repeated measures, within factors one way ANOVA, with an effect size (f) of 0.70, alpha level of 0.05, power at 80% and 1 group with four measurements, 5 participants were needed.

Hypotheses 1a and 1b: A priori power analysis using G\*Power shows that for a one-tailed difference between 2 means (pairwise) t test, with an effect size of dz = 1.4, alpha of 0.025, power at 80%, a total sample size of 7 participants was required.

### Hypothesis 2

This was the first study to investigate illusory finger stretching using SSEPs, so appropriate effect size estimates were not available. We therefore conducted power calculations based on a smallest effect size of interest, in line with the recommendation of @lakens2014a. Here, we have chosen an effect size of d = 0.5 (a medium effect, see Cohen, 1988), since this is the smallest effect size we were interested in detecting, which we converted to a Cohen’s f of 0.25 for Hypothesis 2’s power analysis, and have maintained at 0.5 for the subsequent post hoc power analyses. 

Hypothesis 2: A priori power analysis using G\*Power showed that for a repeated measures, within factors one way ANOVA, with an effect size (f) of 0.25, alpha of 0.05, power at 80%, and 1 group with four measurements, a total sample size of 24 participants was needed. 

Hypotheses 2a – 2c: A priori power analysis using G\*Power shows that for a two-tailed difference between 2 means (pairwise) t test, with an effect size of dz = .5, alpha of 0.016 (corrected for multiple comparisons), power at 80%, a total sample size of 46 participants was needed.



# Results

Positive control analyses of the subjective illusion data can be seen in @fig-illusion. A one-way ANOVA found a significant overall effect of condition with a large effect size (*F*(`r round(res.aov1$ANOVA$DFn[1])`,`r round(res.aov1$ANOVA$DFd[1])`), *p.adj* = `r format.pval(res.aov1$ANOVA$p[1], digits = 1, eps = 0.001, nsmall = 3)`, $ηp^2$ = `r res.aov1$ANOVA$pes[1]`). Post hoc t tests with Bonferroni corrections found significantly greater combined illusion score in the MS condition (M = `r round(illusionmsds$mean[3],digits = 2)`, SD = `r round(illusionmsds$sd[3],digits = 2)`) compared to the Non-Illusion (NI; M = `r round(illusionmsds$mean[1],digits = 2)`, SD = `r round(illusionmsds$sd[1],digits = 2)`, *t* = `r round(pwc1$statistic[2], digits = 2)`, *p.adj* = `r format.pval(pwc1$p.adj[2], digits = 1, eps = 0.001, nsmall = 3)`, Cohen's d = `r round(MSNIes$d[1], digits = 2)`) and Non Illusion Tactile (NIT; M = `r round(illusionmsds$mean[2],digits = 2)`, SD = `r round(illusionmsds$sd[2],digits = 2)`, *t* = `r round(pwc1$statistic[4], digit = 2)`, *p.adj* = `r format.pval(pwc1$p.adj[4], digits = 1, eps = 0.001, nsmall = 3)`, Cohen's d = `r round(MSNITes$d[1], digits = 2)`) conditions, thereby supporting hypotheses 1, 1a, and 1b and fulfilling the positive control checks.


![Combined Illusion Score Index Across Conditions (NI: Non-Illusion; NIT: Non-Illusion Tactile; MS: Multisensory; UV: Unimodal Visual). Scores below 50 indicate disagreement with experience of illusion statements, whilst scores above 50 indicate agreement. A continuous visual analogue scale was used in data collection, with agreement and disagreement statements located at each end of the scale. Box plots show means, medians and inter-quartile ranges of data. Medians are indicated with a horizontal line whilst means are indicated by a black dot. Data points are shown in grey jitter binned along the y-axis, grouped by condition. ](Figures/illusiondata.pdf){#fig-illusion}


Analyses of SSEP data can be seen in @fig-eeg1. The left panel confirms the presence of a clear steady-state signal at 26Hz, which was strongest over the fronto-central electrodes. A one-way ANOVA found no significant effect of condition with a small effect size (*F*(`r round(res.aov4$ANOVA$DFn[1])`,`r round(res.aov4$ANOVA$DFd[1])`), *p* = `r format.pval(res.aov4$ANOVA$p[1], digits = 1, eps = 0.001, nsmall = 3)`, $ηp^2$ = `r res.aov4$ANOVA$pes[1]`), opposing Hypothesis 2. Post hoc t tests with Bonferroni corrections found no significant differences between SSEP amplitude when comparing the NI condition (M = `r round(eegdatamsds$mean[1],digits = 2)`, SD = `r round(eegdatamsds$sd[1],digits = 2)`) to the MS condition (M = `r round(eegdatamsds$mean[3],digits = 2)`, SD = `r round(eegdatamsds$sd[3],digits = 2)`, *t* = `r round(pwc4$statistic[2], digits = 2)`, *p.adj* = `r format.pval(pwc4$p.adj[2], digits = 1, eps = 0.001, nsmall = 3)`, Cohen's d = `r round(eegMSNIes$d[1],digits = 2)`), or UV condition (M = `r round(eegdatamsds$mean[4],digits = 2)`, SD = `r round(eegdatamsds$sd[4],digits = 2)`, *t* = `r round(pwc4$statistic[3], digits = 2)`, *p.adj* = `r format.pval(pwc4$p.adj[3], digits = 1, eps = 0.001, nsmall = 3)`, Cohen's d = `r round(eegUVNIes$d[1],digits = 2)`), meaning Hypotheses 2a and 2b were unsupported. There was no significant difference found when comparing the NI condition to the NIT condition (M = `r round(eegdatamsds$mean[2],digits = 2)`, SD = `r round(eegdatamsds$sd[2],digits = 2)`, *t* = `r round(pwc4$statistic[1], digits = 2)`, *p.adj* = `r format.pval(pwc4$p.adj[1], digits = 1, eps = 0.001, nsmall = 3)`, Cohen's d = `r round(eegNINITes$d[1],digits = 2)`), supporting Hypothesis 2c. 

::: {#fig-confirmeeg layout-valign="bottom" layout="[[48,-4,48], [100]]"}

![](Figures/spectrum1.pdf){#fig-spectrum1}

![](Figures/eegdata1.pdf){#fig-eeg1}

(a): SSEP Amplitude Spectra Across Conditions (NI: Non-Illusion; NIT: Non-Illusion Tactile; MS: Multisensory; UV: Unimodal Visual) for electrodes of interest (F1 & FC1). Shading shows ±1 standard error across participants (n=46). (b): SSEP Amplitudes Across Conditions. Box plots show menas, medians and inter-quartile ranges of data. Medians are indicated with a horizontal line whilst means are indicated by a black dot. Data points are shown in grey jitter binned along the y-axis, grouped by condition.  
:::

## Exploratory Analyses

Since illusion data violated assumptions for parametric tests, an exploratory Friedman test was run and found a significant overall effect of condition with a moderate effect size ($\chi^2$(`r round(res.fried_illusion$df[1],digits = 2)`) = `r round(res.fried_illusion$statistic[1],digits = 2)`, *p* = `r format.pval(res.fried_illusion$p[1], digits = 1, eps = 0.001, nsmall = 3)`, Kendall’s W = `r round(effectsize_illusion$effsize[1],digits = 2)`) and post hoc Wilcoxon tests with Holm corrections found significantly greater combined illusion score in the Multisensory Stretching (MS) condition (M = `r round(illusionmsds$median[3],digits = 2)`, SD = `r round(illusionmsds$sd[3],digits = 2)`) compared to the Non-Illusion (NI; M = `r round(illusionmsds$median[1],digits = 2)`, SD = `r round(illusionmsds$sd[1],digits = 2)`, *z* = `r round(nppwc_illusion$statistic[2], digits = 2)`, *p.adj* = `r format.pval(nppwc_illusion$p.adj[2], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_illusion_es$effsize[2],digits = 2)`), Non Illusion Tactile (NIT; M = `r round(illusionmsds$median[2],digits = 2)`, SD = `r round(illusionmsds$sd[2],digits = 2)`, *z* = `r round(nppwc_illusion$statistic[4], digits = 2)`, *p.adj* = `r format.pval(nppwc_illusion$p.adj[4], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_illusion_es$effsize[4],digits = 2)`) and UV conditions (UV; M = `r round(illusionmsds$median[4],digits = 2)`, SD = `r round(illusionmsds$sd[4],digits = 2)`, *z* = `r round(nppwc_illusion$statistic[6], digits = 2)`, *p.adj* = `r format.pval(nppwc_illusion$p.adj[6], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_illusion_es$effsize[6],digits = 2)`). 

In addition to illusion data, disownership and control data were collected and therefore analyses on these datasets have also been run. Exploratory analysis of subjective disownership and control data can be seen in Appendix C. A significant increase in disownership scores were found in the UV condition compared to all other conditions, and there were no significant comparisons found for control data. All statistical reporting can be seen in Appendix C. 

EEG data also violated assumptions for parametric tests and therefore a Friedman test was also run and found a significant overall effect of condition with a small effect size ($\chi^2$(`r round(res.fried_eeg1$df[1],digits = 2)`) = `r round(res.fried_eeg1$statistic[1],digits = 2)`, *p* = `r format.pval(res.fried_eeg1$p[1], digits = 1, eps = 0.001, nsmall = 3)`, Kendall’s W = `r round(effectsize_eeg1$effsize[1],digits = 2)`), however, post hoc Wilcoxon tests with Holm corrections found no significant differences between SSEP amplitude when comparing the NI condition (M = `r round(eegdatamsds$median[1],digits = 2)`, SD = `r round(eegdatamsds$sd[1],digits = 2)`) to the MS condition (M = `r round(eegdatamsds$median[3],digits = 2)`, SD = `r round(eegdatamsds$sd[3],digits = 2)`, *z* = `r round(nppwc_eeg1$statistic[1], digits = 2)`, *p.adj* = `r format.pval(nppwc_eeg1$p.adj[1], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_eeg1_es$effsize[1],digits = 2)`), or UV condition (M = `r round(eegdatamsds$median[4],digits = 2)`, SD = `r round(eegdatamsds$sd[4],digits = 2)`, *z* = `r round(nppwc_eeg1$statistic[2], digits = 2)`, *p.adj* = `r format.pval(nppwc_eeg1$p.adj[2], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_eeg1_es$effsize[2],digits = 2)`). There was no significant difference found when comparing the NI condition to the NIT condition (M = `r round(eegdatamsds$median[2],digits = 2)`, SD = `r round(eegdatamsds$sd[2],digits = 2)`, *z* = `r round(nppwc_eeg1$statistic[3], digits = 2)`, *p.adj* = `r format.pval(nppwc_eeg1$p.adj[3], digits = 1, eps = 0.001, nsmall = 3)`, r = `r round(nppwc_eeg1_es$effsize[3],digits = 2)`). 

Exploratory correlational analyses were also conducted to assess the correlation between participant’s subjective illusion score and their SSEP amplitude across electrodes of interest (F1 & FC1) for each condition to see if those who experienced a stronger feeling of the illusion had more reduced SSEP amplitudes, results showed no significant correlations and can be seen in Appendix D.

<!-- Despite our pilot data showing the strongest SSEP response to be over electrodes F1 and FC1, the headplots in Figure 4 indicate the strongest responses to be more central for this dataset. Previous research assessing somatosensory SSEP responses has found activation to be slightly more central than electrodes F1 and FC1 [@porcu2014a; @timora2018a], In line with the findings within this dataset. Therefore, exploratory analysis was conducted to assess which electrodes gave the greatest overall response, which resulted in electrodes FPZ and FCZ being used for further exploratory analysis. Exploratory analysis can be seen in @fig-eeg2. A Friedman test found no overall effect of condition with a small effect size ($\chi^2$(`r round(res.fried_eeg2$df[1],digits = 2)`) = `r round(res.fried_eeg2$statistic[1],digits = 2)`, *p* = `r format.pval(res.fried_eeg2$p[1], digits = 1, eps = 0.001, nsmall = 3)`, Kendall’s W = `r round(effectsize_eeg2$effsize[1],digits = 2)`). Post hoc Wilcoxon tests with holm corrections found no significant differences between SSEP amplitude when comparing the NI condition (M = `r round(eegdatamsds2$median[1],digits = 2)`, SD = `r round(eegdatamsds2$sd[1],digits = 2)`) to the NIT condition (M = `r round(eegdatamsds2$median[2],digits = 2)`, SD = `r round(eegdatamsds2$sd[2],digits = 2)`, *p* = `r format.pval(nppwc2_eeg2$p.adj[3], digits = 1, eps = 0.001, nsmall = 3)`), MS condition (M = `r round(eegdatamsds2$median[3],digits = 2)`, SD = `r round(eegdatamsds2$sd[3],digits = 2)`, *p* = `r format.pval(nppwc2_eeg2$p.adj[1], digits = 1, eps = 0.001, nsmall = 3)`), or UV condition (M = `r round(eegdatamsds2$median[4],digits = 2)`, SD = `r round(eegdatamsds2$sd[4],digits = 2)`, *p* = `r format.pval(nppwc2_eeg2$p.adj[2], digits = 1, eps = 0.001, nsmall = 3)`).  -->

<!-- ::: {#fig-exploreeeg layout-valign="bottom" layout="[[48,-4,48], [100]]"} -->

<!-- ![](Figures/spectrum2.pdf){#fig-spectrum2} -->

<!-- ![](Figures/eegdata2.pdf){#fig-eeg2} -->

<!-- (a): Exploratory SSEP Amplitude Spectra Across Conditions for electrodes of interest (FCZ & FPZ). Shading shows standard error. (b): Exploratory SSEP Amplitudes Across Conditions. Box plots show means, medians and inter-quartile ranges of data. Medians are indicated with a horizontal line whilst means are indicated by a black dot. Data points are shown in grey jitter.   -->
<!-- ::: -->

# Discussion

This study sought to understand both subjective and neural responses to resizing illusions in participants without chronic pain, to provide not only a greater understanding of how bodily illusions affect cortical representations, but also a basis for investigating differences in cortical representations between participants with and without chronic pain conditions when using resizing illusions for analgesic treatment. Subjective data replicated previous findings of greater subjective illusory experience in multisensory compared to non-illusion conditions, showing that the addition of vibrotactile stimulation does not appear to impact subjective experience of resizing illusions using augmented reality, since these effects replicate ones found previously without vibrotactile stimulation. Confirmatory EEG analyses showed no significant effect of condition when assessing SSEP amplitudes across the electrodes of interest (F1 & FC1) at 26Hz. Exploratory non-parametric analyses of SSEP amplitudes, however, showed a significant effect of condition with a decreased median amplitude in the multisensory and unimodal visual conditions compared to the non-illusion condition. However, these differences did not reach statistical significant with exploratory post hoc tests. These findings, therefore, suggest that illusory resizing can lead to reductions in SSEP amplitude, but replication within confirmatory analyses is needed.

Whilst the subjective illusory experience data supported the positive control hypothesis of the multisensory condition providing greater illusory experience than either of the non-illusion conditions, exploratory analyses found that the unimodal-visual condition demonstrated a significantly reduced experience of the illusion compared to the multisensory condition. This reduction in illusory experience for the unimodal visual condition compared to the multisensory condition was also found in our previous work [@hansford2023a], and similarly shows a more diverse range of responses compared to the multisensory condition. These findings reinforce the idea that not everyone experiences resizing illusions with only visual stimuli, and this should be considered when assessing the application of resizing illusions to chronic pain samples, as if subjective experience of the illusion is required for analgesic effects, then it is possible that not everyone will experience this from a unimodal visual presentation. Exploratory data looking at disownership of the digit during illusory resizing found significantly greater experiences of disownership in the unimodal visual condition compared to the multisensory, non-illusion, and non-illusion tactile conditions. This heightened disownership might explain the reduced illusory experience in the unimodal visual condition, as it could be that the presence of tactile input is needed during illusory resizing to ground the digit within the augmented reality system, otherwise feelings of disownership can arise. 

Regarding SSEP data, the reduced amplitudes seen in the exploratory analyses could be explained through the somatosensory blurring / sharpening hypothesis [@haggard2013a]. This theory proposes that the somatosensory representation of a body part can be sharpened through improved tactile discrimination and acuity training. This sharpening is thought to represent increased organisation of the somatosensory area responding to the stimuli [@haggard2013a]. Tactile acuity can be increased through simply viewing an enlarged body part [@kennett2001a]. Therefore, it is likely that the enlarged digits created through illusory resizing are sharpening the somatosensory representations of the digits. The reduced amplitudes found during exploratory analyses in the illusory conditions compared to the non-illusion conditions therefore could demonstrate a neural representation of this somatosensory sharpening. However, since these differences were not found to be significant through confirmatory analyses or exploratory post hoc tests, it is possible that for people without chronic pain there are not clear changes in SSEP response during illusory resizing. Furthermore, since the effect sizes were small for the SSEP analysis it is possible that whilst somatosensory sharpening might contribute to our experiences of resizing illusions, there could be other mechanisms involve that the present study does not address. 

A possible explanation for the SSEP reductions found could be through the direction of attention to the digits in illusory conditions. However, previous research has found that attending to a specific vibrotactile stimulus can result in an increase, rather than a reduction, in SSEP amplitude [@giabbiconi2004a]. Furthermore, brain computer interfaces (BCIs) are used to intentionally modify a brain signal that can be detected by a computer to manipulate one’s environment, and these are often based on increasing SSEP response amplitudes through directing attention [@muller-putz2006a]. Therefore, it is unlikely that the reduction in SSEP amplitudes seen here are due to increased attention in tactile and illusory manipulation conditions. It is possible though, that if somatosensory sharpening is occurring, the reduction in amplitude associated with this could be confounded by this attentional effect, with somatosensory sharpening reducing amplitudes whilst attention is increasing the amplitudes, resulting in the small effect sizes we see within this dataset. Due to these small effect sizes, replication of these effects in larger samples might be better able to assess somatosensory sharpening or attentional effects, as here the sample size was only powered to detect at least medium effects. 

Further exploratory analyses assessed correlations between subjective illusory experience and SSEP amplitude across electrodes of interest and found no significant correlations for any condition. These findings could indicate that subjective experience of the illusion is not required for there to be changes in cortical responses, although without clear support for changes in SSEP amplitudes found within the confirmatory analyses, this suggestion cannot be empirically justified. It is possible that SSEP amplitudes are too noisy to show such somatosensory changes, or that the sample needed to detect these effects would have to be larger than the one in the present study. However, when considering resizing illusions as a non-pharmaceutical method for pain reduction, a lack of correlation between SSEP amplitude and illusory experience could mean that patients do not need to subjectively experience resizing illusions for there to be the potential of illusory analgesia. Future research is needed to consolidate both this hypothesis and the exploratory correlational findings from the present study.

One of the main aims of the present study was to provide a basis for investigating somatosensory representations of illusory resizing in samples with hand-based chronic pain. Illusory resizing has been found to provide analgesic effects for hand-based chronic pain [@preston2011a], however the neural underpinnings of this analgesia remain undefined. Since chronic pain is thought to create blurred somatosensory representations of the painful body part [@haggard2013a], it is possible that when comparing the results seen here in participants without chronic pain to a sample of participants with chronic pain, the differences between amplitudes in the non-illusion and illusion conditions could be greater, due to more blurred initial representations of the painful digits. If somatosensory response changes are found in a sample with chronic pain, then these changes could underscore the analgesia experienced after illusory resizing, however if these changes are either not seen or do not align with pain reduction, then alternate mechanisms are likely behind illusory resizing analgesia. It is, however, possible that since there were no SSEP effects found through confirmatory analyses in the present study, that the impact of illusory resizing on SSEP responses could be too small to meaningfully detect in both population groups, especially since a patient group could have more varied and / or noisy data. 

# Conclusions

The present study enhances our understanding of whether there are cortical changes associated with illusory resizing in people without chronic pain and provides an empirical basis for later investigations of somatosensory response changes in a sample with chronic pain. The subjective data suggest that vibrotactile stimulation does not affect experience of resizing illusions, and therefore highlights the suitability of this method for eliciting somatosensory steady state evoked potentials in future investigations. Confirmatory analyses of SSEP data showed no clear effect of illusory resizing on SSEP amplitudes, however, trends toward supporting the somatosensory blurring / sharpening hypothesis were found within exploratory analyses whereby reduced amplitudes were seen in both illusory conditions compared to the non-illusion conditions. If similar reductions are observed in a sample with chronic hand-based pain, then it would be possible to assume that these neural response changes could be driving illusory analgesia.

{{< pagebreak >}}

# Appendix 

Pilot data regarding the experience of the illusion for healthy participants undergoing synchronous and asynchronous illusory resizing of the index finger can be seen in Figure 7. 9 participants had either synchronous or asynchronous multimodal manipulations delivered first in a random order, and were then given the other condition, after which all participants were given an illusion scale. Findings showed that across all participants, no significant difference in illusion experience between the synchronous and asynchronous conditions, t(8) = 1.877, p = 0.097, however as can be seen in figure A1, despite the small sample size, illusion strength was seen to be greater in the synchronous condition compared to the asynchronous condition.

![Pilot data from Healthy Participants Undergoing Synchronous and Asynchronous Illusory Finger Resizing.](Figures/Pilot Data.png){#fig-pilot}
{{< pagebreak >}}

Previous literature stated that the ideal vibration frequency to use to elicit somatosensory SSEPs is approximately 26Hz (Muller et al., 2001; Breitweiser et al., 2016; Pokorny et al., 2016; Snyder, 1992).  Due to resizing illusions often manipulating the index finger, and previous studies using the index finger supporting around 26Hz as an optimal frequency (Muller et al., 2001; Breitweiser et al., 2016; Pokorny et al., 2016), it was hypothesised that 26Hz would elicit a dependable somatosensory SSEP response. Therefore, we ran a pilot study to check that our setup and equipment can reliably elicit and record a somatosensory SSEP at 26Hz, using the resizing illusion and EEG.

Pilot data were collected for 3 healthy participants. Participants underwent the same experimental protocol as mentioned in the “Experimental Procedure” section, minus the subjective illusory experience questionnaire. A Fourier transform was calculated for each waveform at each electrode for all conditions, and then averaged across repetition to obtain individual results. These were then averaged across all 3 participants to give the result seen in Figure 8. 

As can be seen in Figure 8, there was a clear somatosensory SSEP response at 26Hz, which was strongest around electrodes F1 and FC1. Previous research using vibrotactile stimulation at 21Hz have also found the scalp topography of the activation to be most pronounced over mid-frontal distributions (Porcu et al., 2014; Timora & Budd, 2018), in line with the scalp topography seen here. Given these finding of a distinct 26Hz signal and mid-frontal scalp location, it appeared appropriate for 26Hz to be used as the vibration frequency in the current study. 

![Averaged Pilot Data showing peak frequency at 26Hz, centred between electrodes F1 and FC1. The spectrum is derived from electrode FC1. Saturation bar represents signal to noise ratio (SNR). SNR is a measure of signal quality and describes the ratio of signal power (at 26Hz) to noise power (averaged across 10 adjacent frequency bins). SNR was used for the pilot figure because with a small sample (3 participants) we did not want a noisy electrode to influence the electrodes chosen as electrodes of interest.](Figures/Pilot Data 2.png){width=50%, height=50%}

{{< pagebreak >}}

Pilot data were also collected using the vibrotactile stimulator at 26Hz to make sure that the illusory experience is not affected by the addition of vibrotactile input. Pilot data were collected from 4 additional healthy participants, who underwent the same experimental protocol as mentioned in the “Experimental Procedure” section, but without EEG caps fitted. Illusory experience was calculated using the median of both illusion scores for each participant minus their median control scores, as per the preprocessing steps regarding the control index, and then the data were averaged over participants to give the results seen in Figure 9. As can be seen, there is a greater subjective experience of the resizing illusion, indexed by participant’s illusion score, in both experimental conditions (UV average = 64.25; MS average = 67.88) compared to both control conditions (NI average = 32.38; NIT average = 24.13). Scores below 50 are indicative of disagreement of experience of the illusion, whilst a score of 50 is a neutral option regarding the illusion experience, and scores above 50 are indicative of agreement of experiencing the illusion. This therefore shows that the experience of illusory resizing was maintained when vibrotactile stimulation was added to the procedure and can therefore be used in the current study to elicit somatosensory SSEPs without affecting the subjective illusory experience of the resizing illusion. 

![Averaged Illusion score for each condition. Error bars represent standard errors. NI represents the non-Illusion condition, NIT refers to the non-illusion tactile condition, UV refers to the unimodal-visual condition, and MS refers to the multisensory condition.](Figures/Pilot Data 3.png){#fig-pilot3}

{{< pagebreak >}}

A visual schematic of the hypotheses can be seen below:

![Visual Schematic of Hypotheses.](Figures/Hypotheses Schematic.png){#fig-hypschematic}

{{< pagebreak >}}

Exploratory analyses of the subjective disownership data using a Friedman test found a significant overall effect of condition with a small effect size ($\chi^2$(`r round(res.fried_disownership$df[1],digits = 2)`) = `r round(res.fried_disownership$statistic[1],digits = 2)`, *p* = `r format.pval(res.fried_disownership$p[1], digits = 1, eps = 0.001, nsmall = 3)`, Kendall’s W = `r round(effectsize_disownership$effsize[1],digits = 2)`) and post hoc Wilcoxon tests with Holm corrections found significantly greater combined disownership score in the UV condition (Median = `r round(disownershipmsds$median[4],digits = 2)`, SD = `r round(disownershipmsds$sd[4],digits = 2)`) compared to the NI (Median = `r round(disownershipmsds$median[1],digits = 2)`, SD = `r round(disownershipmsds$sd[1],digits = 2)`, *z* = `r round(nppwc_disownership$statistic[3], digits = 2)`, *p.adj* = `r format.pval(nppwc_disownership$p.adj[3], digits = 1, eps = 0.001, nsmall = 3)`, *r* = `r round(nppwc_disownership_es$effsize[3], digits = 2)`), NIT (M = `r round(disownershipmsds$median[2],digits = 2)`, SD = `r round(disownershipmsds$sd[2],digits = 2)`, *z* = `r round(nppwc_disownership$statistic[5], digits = 2)`, *p.adj* = `r format.pval(nppwc_disownership$p.adj[5], digits = 1, eps = 0.001, nsmall = 3)`, *r* = `r round(nppwc_disownership_es$effsize[5], digits = 2)`), and MS conditions, (Median = `r round(disownershipmsds$median[3],digits = 2)`, SD = `r round(disownershipmsds$sd[3],digits = 2)`, *z* = `r round(nppwc_disownership$statistic[6], digits = 2)`, *p.adj* = `r format.pval(nppwc_disownership$p.adj[6], digits = 1, eps = 0.001, nsmall = 3)`, *r* = `r round(nppwc_disownership_es$effsize[6], digits = 2)`).

![Combined Disownership Score Index Across Conditions (NI: Non-Illusion; NIT: Non-Illusion Tactile; MS: Multisensory; UV: Unimodal Visual). Scores below 50 indicate disagreement with experience of disownership statements, whilst scores above 50 indicate agreement. A continuous visual analogue scale was used in data collection, with agreement and disagreement statements located at each end of the scale. Box plots show means, medians and inter-quartile ranges of data. Medians are indicated with a horizontal line whilst means are indicated by a black dot. Data points are shown in grey jitter binned along the y-axis, grouped by condition. ](Figures/disownershipdata.pdf){#fig-disownership}

{{< pagebreak >}}

Exploratory analyses of the subjective control data using a Kruskall-Wallis test (due to multiple ties) found no significant overall effect of condition  ($\chi^2$(`r round(kruskall.wallis$parameter[1],digits = 2)`) = `r round(kruskall.wallis$statistic[1],digits = 2)`, *p* = `r format.pval(kruskall.wallis$p.value[1], digits = 1, eps = 0.001, nsmall = 3)`) and post hoc Dunn's tests with Bonferroni corrections found no significant differences between combined control scores when comparing the NI condition (Median = `r round(controlmsds$median[1],digits = 2)`, SD = `r round(controlmsds$sd[1],digits = 2)`) to the NIT condition (Median = `r round(controlmsds$median[2],digits = 2)`, SD = `r round(controlmsds$sd[2],digits = 2)`, *z* = `r round(nppwc_controlD$res$Z[3], digits = 2)`, *p.adj* = `r format.pval(nppwc_controlD$res$P.adj[3], digits = 1, eps = 0.001, nsmall = 3)`), or the MS (Median = `r round(controlmsds$median[3],digits = 2)`, SD = `r round(controlmsds$sd[3],digits = 2)`, *z* = `r round(nppwc_controlD$res$Z[1], digits = 2)`, *p.adj* = `r format.pval(nppwc_controlD$res$P.adj[1], digits = 1, eps = 0.001, nsmall = 3)`), or UV conditions (Median = `r round(controlmsds$median[4],digits = 2)`, SD = `r round(controlmsds$sd[4],digits = 2)`, *z* = `r round(nppwc_controlD$res$Z[5], digits = 2)`, *p.adj* = `r format.pval(nppwc_controlD$res$P.adj[5], digits = 1, eps = 0.001, nsmall = 3)`).

![Combined Control Scores Across Conditions (NI: Non-Illusion; NIT: Non-Illusion Tactile; MS: Multisensory; UV: Unimodal Visual). Scores below 50 indicate disagreement with experience of control statements, whilst scores above 50 indicate agreement. A continuous visual analogue scale was used in data collection, with agreement and disagreement statements located at each end of the scale. Box plots show means, medians and inter-quartile ranges of data. Medians are indicated with a horizontal line whilst means are indicated by a black dot. Data points are shown in grey jitter binned along the y-axis, grouped by condition. ](Figures/controldata.pdf){#fig-control}

{{< pagebreak >}}

Spearman’s correlations were run to identify any correlations between participant’s illusion score and their SSEP amplitude across electrodes of interest (F1 & FC1) for each condition found no significant correlations across conditions.

![Correlation Between Amplitude and Subjective Illusory Score for Each Condition (NI: Non-Illusion; NIT: Non-Illusion Tactile; MS: Multisensory; UV: Unimodal Visual).](Figures/correlationdata.pdf){#fig-correlation}

{{< pagebreak >}}

# References

